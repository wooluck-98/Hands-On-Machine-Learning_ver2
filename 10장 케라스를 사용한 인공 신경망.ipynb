{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# 일관된 출력을 위해 유사난수 초기화\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "sn.set()\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# 한글출력\n",
    "# matplotlib.rc('font', family='AppleGothic')  # MacOS\n",
    "matplotlib.rc('font', family='Malgun Gothic')  # Windows\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10.1 생물학적 뉴런에서 인공 뉴런까지\n",
    "\n",
    "* 인공 신경망(ANN, Aritificial Neural Networks)은 1943년 신경생리학자 Warren McCulloch과 수학자 Walter Pitts가 'A Logical Calculus of Ideas Immanent In Nervous Activity' 처은 소개했으며, 명제 논리(propositional logic)를 사용해 동물 뇌의 생물학적 뉴런이 복잡한 계산을 위해 어떻게 상호작용하는지에 대해 간단한 계산 모델을 제시했다.\n",
    "* 1960년대까지는 이렇게 등장한 인공 신경망을 통해 사람들은 지능을 가진 기계와 대화를 나눌 수 있을 것이라고 생각했다. 하지만 아래 그림(출처: beamandrew's blog)처럼 사람들의 기대와는 달리 인공 신경망으로 XOR문제를 해결할 수 없게 되었고, 1990년 대에는 SVM과 성능이 좋은 다른 머신러닝 알고리즘들이 나오게 되면서 인공 신경망은 암흑기로 접어 들게 되었다.\n",
    "* 2000년 대에 들어서면서 인공 신경망은 2012년 ILSVRC2012 대회에서 인공 신경망을 깊게 쌓은 딥러닝 모델인 AlexNet이 압도적인 성적으로 우승하면서 다시금 주목받게 되었다. 이렇게 인공 신경망(딥러닝)이 다시 주목받게 된 계기는 다음과 같은 것들이 있다.\n",
    "\n",
    " - 빅 데이터 시대인 요즘 신경망을 학습시키기 위한 데이터가 엄청나게 많아 졌다.\n",
    " - 신경망은 다른 머신러닝 알고리즘보다 규모가 크고 복잡한 문제에서 성능이 좋다. \n",
    " - 1990년대 이후 크게 발전된 컴퓨터 하드웨어 성능과 Matrix연산에 고성능인 GPU로 인해 상대적으로  짧은 시간 안에 대규모의 신경망을 학습시킬 수 있게 되었다.\n",
    "<img src = 'images/10_images/history.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.1.1 생물학적 뉴런\n",
    "\n",
    "* 인공 뉴런에 관해 이야기하기 전에 생물학적 뉴런을 살펴봐야한다. 이 세포는 핵을 포함하는 세포체와 복잡한 구성 요소로 이루어져 있다.\n",
    "* 생물학적 뉴런은 활동 전위(Action Potential, AP) 또는 간단히 신호(Signal)라고 부르는 짧은 전기 자극을 만든다. 이 신호는 축삭돌기를 따라 이동하여 시냅스가 신경전달물질(Neurotransmitter)이라는 화학적 신호를 발생하게 한다.\n",
    "* 뉴런은 일천 분의 몇 초 동안 충분한 양의 신경전달물질을 받았을 때 자제적인 신호를 발생한다.\n",
    "<img src = 'images/10_images/neuron.png'>\n",
    "\n",
    "* 그리고 이 뉴런은 보통 다른 뉴런 네트워크 수천 개와 연결되어, 단순한 뉴런으로 구성된 거대한 네트워크가 매우 복잡한 계산을 수행할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.1.2 뉴런을 사용한 논리 연산\n",
    "\n",
    "* 메컬러와 피츠가 생물학적 뉴런에서 착안한 매우 단순한 신경망 모델을 제안했는데, 이것이 나중에 인공 뉴런(Artificial Neuron)이 되었다.\n",
    "* 이 모델은 하나 이상의 이진(On / Off) 입력과 이진 출력 하나를 가진다.\n",
    "* 인공 뉴런은 단순히 입력이 일정 개수만큼 활성화되었을 때 출력을 내보낸다.\n",
    "\n",
    "<img src = 'images/10_images/mlst_1003.png'>\n",
    "\n",
    "* 이런 간단한 모델로 인공 뉴런의 네트워크를 만들어 어떤 논리 명제도 계산할 수 있다.\n",
    "\n",
    " 1. 항등함수 : 뉴런 A가 활성화 되면 뉴런 C도 활성화 된다.\n",
    " 2. 논리곱 연산 : 뉴런 A, B가 모두 활성화될 때만 뉴런 C가 활성화된다.\n",
    " 3. 논리합 연산 : 뉴런 A 와 B 중 하나가 활성화되면 뉴런 C가 활성화된다.\n",
    " 4. 뉴런의 활성화를 억제할 수 있다고 가정 : 뉴런 A가 활성화, 뉴런 B가 비활성화될 때 뉴런 C가 활성화된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.1.3 퍼셉트론\n",
    "\n",
    "* 퍼셉트론(Perceptron)은 가장 간단한 인공 신경망 구조 중 하나로 1957년에 프랑크 로젠블라트(Frank Rosenblatt)가 제안했다.\n",
    "* 퍼셉트론은 TLU(Threshold Logic Unit), LTU(Linear Threshold Unit)라고 불리는 조금 다른 형태의 인공 뉴런을 기반으로 한다.\n",
    " - TLU : 입력의 가중치 합을 계산한 다음 계단 함수를 적용하는 인공 뉴런\n",
    "* 입력과 출력이 어떤 숫자이고, 각각의 입력 연결은 가중치(W, Weight)와 연관되어 있어, 입력의 가중치 합을 계산한뒤 계산된 합에 계단 함수(Step Function)를 적용하여 결과를 출력한다.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "h_w(\\mathbf{X}) &amp;= \\text{step}(z) \\\\ &amp;= \\text{step}(\\mathbf{W}^{T} \\cdot \\mathbf{X})\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "<img src = 'images/10_images/perceptron02.png'>\n",
    "\n",
    "* 헤비사이드 계단 함수(Heaviside Step Function) : 퍼셉트론에서 가장 널리 사용되는 계단 함수, 부호 함수(Sign Function)를 대신 사용하기도 한다.\n",
    "$$\n",
    "\\text{heaviside}(z)=\\begin{cases} 0 \\text{  (}z < 0)  \\\\ 1 \\text{  (}z ≥ 0) \\end{cases}, \\quad \\text{sgn}(z)= \\begin{cases} -1 \\text{  (}z < 0)\\\\  0 \\text{ (}z = 0)\\\\ +1 \\text{  (}z > 0)\\end{cases}\n",
    "$$\n",
    "\n",
    "* 위의 그림에서 처럼, 하나의 TLU는 입력과 가중치의 선형결합인 $z$가 $z \\ge 0$ 이면 양성 클래스, $z < 0$이면 음성 클래스를 출력하게 하는 선형 이진 분류(linear binary classification)에 적용할 수 있다. 이러한 TLU를 학습시킨다는 것은 분류를 잘할 수 있는 최적의 매개변수 $w_1, w_2, \\dots, w_n$을 찾는다는 뜻이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 퍼셉트론은 층이 하나뿐인 TLU로 구성된다. 각 TLU은 모든 입력에 연결되어 있다.\n",
    "* 완전 연결 층(Fully Conected Layer) / 밀집층(Dense Layer) : 한 층에 모든 뉴런이 이전 층의 모든 뉴런과 연결되어 있을 때\n",
    "* 입력 뉴런(Input Neuron) : 퍼셉트론의 입력\n",
    "* 입력층(Input Layer)는 모두 입력 뉴런으로 구성, 보통 거기에 편향 특성이 더해진다.\n",
    "* 아래의 그림은 위의 TLU를 세 개로 구성한 퍼셉트론에 편향($x_0=1$)을 추가한 것이다. 이 퍼셉트론은 샘플 세 개의 클래스(레이블)로 분류할 수 있는 Multioutput Classifier이다.\n",
    "<img src = 'images/10_images/multi-tlu.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 퍼셉트론 학습\n",
    " - 프랑크 로젠블라트가 제안한 퍼셉트론의 훈련 알고리즘은 헤브의 규칙(Hebb's rule)에서 영감을 받았다.\n",
    " -  Donald Hebb는 1949년에 출간한 책 'The Organization of Behavior'에서 뉴런이 다른 뉴런을 활성화시킬 때 이 두 뉴런의 연결이 강해진다고 주장했다. 즉, 두 뉴런이 동일한 출력을 낼 때마다 이 둘 사이의 연결 가중치가 증가하며 이러한 규칙을 헤브의 규칙 또는 헤브 학습(Hebbian Learning)이라고 한다.\n",
    " - 퍼셉트론은 네트워크가 만드는 에러를 반영하도록 학습되며 잘못된 출력을 만드는 연결은 올바른 출력을 만들 수 있도록 가중치를 조정한다.\n",
    " - 한번에 한 개의 샘플이 주입되면 각 샘플에 대해 예측이 만들어지고, 잘못된 예측을 하는 모든 출력 뉴런에 대해 올바른 예측을 만들 수 있도록 입력에 연결된 가중치를 강화시킨다. 규칙은 다음과 같다.\n",
    "$$\n",
    "w_{i,j}^{\\text{(next step)}} = w_{i,j} + \\eta \\left( y_j - \\hat{y}_j \\right) x_i\n",
    "$$\n",
    "   -  $w_{i,j}$ : $i$-번째 입력 뉴런과 $j$-번째 출력 뉴런 사이를 연결하는 가중치\n",
    "   -  $x_i$ : 현재 학습 데이터 샘플의 $i$-번째 뉴런의 입력값\n",
    "   -  $\\hat{y}_j$ : 현재 학습 데이터 샘플의 $j$-번째 출력 뉴런의 출력값\n",
    "   -  $y_j$ : 현재 학습 데이터 샘플의 $j$-번째 출력 뉴런의 실제값\n",
    "   -  $\\eta$ : 학습률, learning rate\n",
    "   \n",
    "* 각 출력 뉴런의 결정 경계는 선형이므로 퍼셉트론도 복잡한 패턴을 학습하지 못한다. 하지만 로젠블라트는 훈련 샘플이 선형적으로 구분될 수 있다면 이 알고리즘이 정답에 수렴한다는 것을 증명했다.\n",
    "* 이를 퍼셉트론 수렴 이론(Perceptron Convergence Theorem)이라고 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron(max_iter=100, random_state=42)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#사이킷런의 Perceptron 클래스\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data[:, (2, 3)]\n",
    "y = (iris.target == 0).astype(np.int)\n",
    "\n",
    "per_clf = Perceptron(max_iter=100, random_state=42)\n",
    "per_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "y_pred = per_clf.predict([[2, 0.5]])\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = -per_clf.coef_[0][0] / per_clf.coef_[0][1]\n",
    "b = -per_clf.intercept_ / per_clf.coef_[0][1]\n",
    "\n",
    "axes = [0, 5, 0, 2]\n",
    "\n",
    "x0, x1 = np.meshgrid(\n",
    "        np.linspace(axes[0], axes[1], 500).reshape(-1, 1),\n",
    "        np.linspace(axes[2], axes[3], 200).reshape(-1, 1),\n",
    "    )\n",
    "X_new = np.c_[x0.ravel(), x1.ravel()]\n",
    "y_predict = per_clf.predict(X_new)\n",
    "zz = y_predict.reshape(x0.shape)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(X[y==0, 0], X[y==0, 1], \"bs\", label=\"Iris-Setosa 아님\")\n",
    "plt.plot(X[y==1, 0], X[y==1, 1], \"yo\", label=\"Iris-Setosa\")\n",
    "\n",
    "plt.plot([axes[0], axes[1]], [a * axes[0] + b, a * axes[1] + b], \"k-\", linewidth=3)\n",
    "from matplotlib.colors import ListedColormap\n",
    "custom_cmap = ListedColormap(['#9898ff', '#fafab0'])\n",
    "\n",
    "plt.contourf(x0, x1, zz, cmap=custom_cmap)\n",
    "plt.xlabel(\"꽃잎 길이\", fontsize=14)\n",
    "plt.ylabel(\"꽃잎 너비\", fontsize=14)\n",
    "plt.legend(loc=\"lower right\", fontsize=14)\n",
    "plt.axis(axes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 1969년 마빈 민스키(Marvin Minsky)와 시모어 페퍼트(Seymour Papert)는 퍼셉트론이 선형 분류기이기 때문에 배타적인 논리합 XOR 분류 문제를 해결할 수 없다는 결정적인 문제점을 지적했다.\n",
    "\n",
    "<img src = 'images/10_images/or-vs-xor.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 하지만 퍼셉트론을 여러 개 쌓아올리면 일부 제약을 줄일 수 있다는 사실이 밝혀지고, 이런 인공 신경망을 다층 퍼셉트론(Multi-Layer Perceptron, MLP)라고 한다.\n",
    "<img src = 'images/10_images/xor_gate3.png'>\n",
    "<img src = 'images/10_images/xor_gate.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.1.4 다층 퍼셉트론과 역전파\n",
    "\n",
    "* 다층 퍼셉트론은 입력층(Input Layer) 하나와 은닉층(Hidden Layer)이라 불리는 하나 이상의 TLU층과 마지막 출력층(Output Layer)로 구성된다.\n",
    "* 입력층과 가까운 층을 보통 하위 층(Lower Layer)라 부르고, 출력에 가까운 층을 상위층(Upper Layer)이라고 부른다.\n",
    "* 은닉층을 여러 개 쌓아 올린 인공 신경망을 심층 신경망(Deep Neural Network, DNN)이라고 한다.\n",
    "* 이를 학습하여 모델을 만드는 것을 딥러닝(Deep-Learning)이라고 한다.\n",
    "<img src = 'images/10_images/mlp.png'>\n",
    "\n",
    " - 피드포워드 신경망(Feedfoward Neural Network, FNN) : 입력에서 출력 한 방향으로만 흐르는 구조"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* MLP를 통해 XOR문제를 해결했지만, 층이 깊어질수록 증가하는 가중치 매개변수의 수로 인해 다층 퍼셉트론을 학습시키기에는 오랜 시간이 걸리는 문제가 발생\n",
    "* 1986년 데이비드 루멜하트(David Rumelhart), 제프리 힌턴, 로날드 윌리엄스(Ronald Williams)가 역전파(Backpropagation) 훈련 알고리즘을 소개하면서, 계산량을 획기적으로 줄일 수 있었다.\n",
    "* 역전파 알고리즘\n",
    " 1. 각 학습데이터 샘플을 네트워크에 입력으로 넣어주고 출력층까지 각 층의 뉴런마다 출력을 계산한다. 이를 순전파(Foward propagation)이라고 한다.\n",
    " 2. 그 다음 네트워크의 마지막 출력층에 대한 결과(예측값)와 실제값과의 차이, 즉 오차(Error)를 계산하는데, 손실함수(Loss function)를 이용하여 계산한다.\n",
    " 3. 그리고 이 오차를 역방향으로 흘러 보내면서, 각  출력 뉴런의 오차에 마지막 입력 뉴런이 얼마나 기여했는지 측정한다. 즉, 각 뉴런의 입력값에 대한 손실함수의 편미분, 그래디언트(Gradient)를 계산하는 것을 말한다. (Backpropagation)\n",
    " 4. 3번과 같은 방법을 입력층에 도달할 때까지 반복해서 역방향으로 흘러 보낸다.\n",
    " 5. 마지막으로, 계산한 그래디언트를 네트워크의 모든 가중치 매개변수에 반영해주는 경사 하강법 단계를 수행한다.\n",
    " \n",
    "    - 에포크(Epoch) : 한 번에 하나의 미니배치씩 진행하여 전체 훈련 세트를 처리하는 각 반복을 뜻한다.\n",
    "    - 은닉층의 연결 가중치를 랜덤하게 초기화하는 것이 중요하다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 활성화 함수(Activation Function)\n",
    "\n",
    "- 역전파 알고리즘이 잘 동작하기 위해서 다층 퍼셉트론의 구조에 변화를 주었는데, 그것이 계단 함수를 로지스틱(시그모이드) 함수로 바꾼 것이다.\n",
    "- 왜냐하면 계단 함수에는 수평선밖에 없으니 계산할 그레디언트가 없기 때문이다.\n",
    "- 활성화 함수로는 다양한 활성화 함수를 사용할 수 있다.\n",
    "\n",
    "<img src = 'images/10_images/activation02.png'>\n",
    "\n",
    "   - 하이퍼볼릭 탄젠트 함수(쌍곡 탄젠트 함수, tanh) : 로지스틱 함수처럼 이 활성화 함수도 S자 모양이고 연속적이며 미분 가능 / 출력 범위가 -1 ~ 1 사이 / 이 범위는 훈련 초기에 각 층의 출력을 원점 근처로 모으는 경향이 있어서 종종 빠르게 수렴되도록 도와준다. \n",
    "   - ReLU 함수 : 연속적이지만, z = 0에서 미분 가능하지 않다 / z < 0 일 경우 도함수는 0 / 실제로 잘 작동하고 계산 속도가 빠르다는 장점이 있어 기본 활성화 함수가 되었다. / 출력에 최댓값이 없다는 점이 경사 하강법에 있는 일부 문제를 완화해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def relu(z):\n",
    "    return np.maximum(0, z)\n",
    "\n",
    "def derivative(f, z, eps=0.000001):\n",
    "    return (f(z + eps) - f(z - eps))/(2 * eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "z = np.linspace(-5, 5, 200)\n",
    "\n",
    "plt.figure(figsize=(11,4))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(z, np.sign(z), \"r-\", linewidth=2, label=\"스텝\")\n",
    "plt.plot(z, logit(z), \"g--\", linewidth=2, label=\"로지스틱\")\n",
    "plt.plot(z, np.tanh(z), \"b-\", linewidth=2, label=\"Tanh\")\n",
    "plt.plot(z, relu(z), \"m-.\", linewidth=2, label=\"ReLU\")\n",
    "plt.grid(True)\n",
    "plt.legend(loc=\"center right\", fontsize=14)\n",
    "plt.title(\"활성화 함수\", fontsize=14)\n",
    "plt.axis([-5, 5, -1.2, 1.2])\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(z, derivative(np.sign, z), \"r-\", linewidth=2, label=\"Step\")\n",
    "plt.plot(0, 0, \"ro\", markersize=5)\n",
    "plt.plot(0, 0, \"rx\", markersize=10)\n",
    "plt.plot(z, derivative(logit, z), \"g--\", linewidth=2, label=\"Logit\")\n",
    "plt.plot(z, derivative(np.tanh, z), \"b-\", linewidth=2, label=\"Tanh\")\n",
    "plt.plot(z, derivative(relu, z), \"m-.\", linewidth=2, label=\"ReLU\")\n",
    "plt.grid(True)\n",
    "plt.title(\"도함수\", fontsize=14)\n",
    "plt.axis([-5, 5, -0.2, 1.2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 소프트맥스(Softmax) 함수\n",
    " - 주로 출력층에서 사용하는 활성화 함수로, 식은 다음과 같다.\n",
    " $$\n",
    "\\hat{y}_k = \\frac{ \\text{exp} \\left( \\mathbf{W}^{T} \\cdot \\mathbf{x} \\right)}{\\sum_{j=1}^{K}{\\text{exp} \\left( \\mathbf{W}^{T} \\cdot \\mathbf{x} \\right)}} \\quad (K=\\text{# of class})\n",
    "$$\n",
    "<img src = 'images/10_images/softmax.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.1.5 회귀를 위한 다층 퍼셉트론\n",
    "\n",
    "* 값하나를 예측하는데 출력 뉴런이 하나만 필요하다. 이 뉴런의 출력이 예측된 값이다.\n",
    "* 다변량 회귀(Miltivariate Regression)에서는 출력 차원마다 출력 뉴런이 하나씩 필요하다.\n",
    "* 일반적으로 회귀용 다층 퍼셉트론을 만들 때 출력 뉴런에 활성화 함수를 사용하지 않고 어떤 범위의 값이 출력되도록 한다. 하지만 출력이 항상 양수여야 한다면 출력층에 ReLU 활성화 함수를 사용할 수 있다. 이처럼 원하는 출력값에 맞춰서 활성화 함수를 설정할 수 있다.\n",
    "* 훈련에 사용하는 손실 함수는 전형적으로 평균 제곱 오차. 하지만 훈련 세트에 이상치가 많다면 대신 평균 절댓값 오차를 사용할 수 있다. 또는 이 둘을 조합한 후버(Huber)손실을 사용할 수 있다.\n",
    "\n",
    "* 회귀 MLP의 전형적인 구조\n",
    " - 입력 뉴런 수 : 특성마다 하나\n",
    " - 은닉층 수 : 문제에 따라 다르다. 일반적으로 1 ~ 5\n",
    " - 은닉층의 뉴런 수 : 문제에 따라 다르다. 일반적으로 10 ~ 100\n",
    " - 출력 뉴런 수 : 예측 차원마다 하나\n",
    " - 은닉층의 활성화 함수 : ReLU 또는 SELU\n",
    " - 출력층의 활성화 함수 : 없음 또는 ReLU/softmax(출력이 양수) 또는 logistic/tanh(출력을 특정 범위로 제한할 때)\n",
    " - 손실 함수 : MES 또는 MAE/Huber(이상치가 있다면)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10.1.6 분류를 위한 다층 퍼셉트론\n",
    "\n",
    "* 이진 분류 문제에서는 로지스틱 활성화 함수를 가진 하나의 출력 뉴런만 필요\n",
    " - 출력은 0 ~ 1 사이의 실수\n",
    " - 양성 클래스에 대한 예측 확률로 해석할 수 있다.\n",
    " - 음성 클래스에 대한 예측 확률은 1에서 양성 클래스의 예측 확률을 뺀 값\n",
    "* 다층 퍼셉트론은 다중 레이블 이진 분류(multilabel Binary Classification) 문제를 쉽게 처리할 수 있다.\n",
    " - 각 샘플이 3개 이상의 클래스 중 한 클래스에만 속할수 있다면 쿨래스마다 하나의 출력 뉴런이 필요\n",
    " - 출력층에는 소프트맥스 활성화 함수를 사용해야 한다.\n",
    " - 확률 분포 예측을 위해 손실 함수에는 크로스 엔트로피 손실 함수(Cross-Entropy Loss, 로그 손실)를 사용한다.\n",
    "\n",
    "* 분류 MLP의 전형적인 구조\n",
    "|하이퍼 파라미터|이진 분류|다중 레이블 분류|다중 분류|\n",
    "|------|------|------|------|\n",
    "|입력층과 은닉층     | 회귀와 동일    | 회귀와 동일     | 회귀와 동일 |\n",
    "|출력 뉴런 수        | 1개            | 레이블마다 1개  | 클래스마다 1개|\n",
    "|출력층의 활성화 함수| 로지스틱 함수  | 로지스틱 함수   | 소프트맥스 함수|\n",
    "|손실 함수           | 크로스 엔트로피| 크로스 엔트로피 | 크로스 엔트로피|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10.2 케라스로 다층 퍼셉트론 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n",
      "2.4.0\n"
     ]
    }
   ],
   "source": [
    "#텐서플로우랑 케라스 임포트하기\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.2.2 시퀀셜 API를 사용하여 이미지 분류기 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#케라스 사용하여 데이터셋 적재하기\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()\n",
    "#28 X 28크기의 배열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "uint8\n"
     ]
    }
   ],
   "source": [
    "#픽셀 강도가 정수(0~255)로 표현\n",
    "print(X_train_full.shape)\n",
    "print(X_train_full.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#전체 훈련 세트를 검증 세트와 훈련 세트로 나누고,\n",
    "#경사 하강법으로 신경망을 훈련하기 위한 입력 특성의 스케일 0~1 사이 범위로 조정하기\n",
    "X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255.0\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#matplotlib의 imshow() 함수와 binary 컬러맵을 사용해 이미지 출력\n",
    "plt.imshow(X_train[0], cmap='binary')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 0, 7, ..., 3, 0, 5], dtype=uint8)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#레이블은 0~9까지 정수로 표현된 클래스 아이디\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Coat'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[y_train[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x345.6 with 40 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#샘플 이미지 출력\n",
    "n_rows = 4\n",
    "n_cols = 10\n",
    "plt.figure(figsize = (n_cols * 1.2, n_rows * 1.2))\n",
    "for row in range(n_rows):\n",
    "    for col in range(n_cols):\n",
    "        index = n_cols * row + col\n",
    "        plt.subplot(n_rows, n_cols, index + 1)\n",
    "        plt.imshow(X_train[index], cmap='binary', interpolation='nearest')\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(class_names[y_train[index]], fontsize=12)\n",
    "plt.subplots_adjust(wspace = 0.2, hspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 시퀀셜 API를 사용하여 모델 만들기\n",
    " 1. Sequential 모델 만들기. 가장 간단한 케라스의 신경망 모델\n",
    " 2. Flatten 층은 입력 이미지를 1D배열로 변환\n",
    " 3. 뉴런 300개를 가진 Dense 은닉층 추가 / ReLU 활성화 함수 사용 / Dense층마다 각자 가중치 행렬 관리\n",
    " 4. 뉴런 100개를 가진 Dense 은닉층 추가\n",
    " 5. 마지막으로 뉴런 10개를 가진 Dense 출력층 추가 / Softmax활성화 함수 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#두 개의 은닉층으로 이루어진 분류용 다층 퍼셉트론\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape = [28, 28]))\n",
    "model.add(keras.layers.Dense(300, activation = \"relu\"))\n",
    "model.add(keras.layers.Dense(100, activation = \"relu\"))\n",
    "model.add(keras.layers.Dense(10, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#층의 리스트를 전달할 수도 있다.\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_3 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#summary() 메서드는 모델에 있는 모든 층을 출력\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.core.Flatten at 0x218907f7220>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x218907f7f10>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x21890824df0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x2189080cb50>]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense_8'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden1 = model.layers[1]\n",
    "hidden1.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer('dense_8') is hidden1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.05207059  0.003291    0.06486709 ... -0.0137484   0.00902148\n",
      "   0.06312418]\n",
      " [ 0.06132056 -0.06125566 -0.00895299 ... -0.06883114  0.03675523\n",
      "  -0.06375062]\n",
      " [-0.0222708  -0.01953053 -0.04256049 ... -0.02442167 -0.01449105\n",
      "  -0.02061009]\n",
      " ...\n",
      " [ 0.05731934 -0.02246214 -0.06358982 ...  0.04602847 -0.04329095\n",
      "  -0.05852254]\n",
      " [-0.02641159  0.01150537  0.02243438 ... -0.04857169 -0.04977864\n",
      "  -0.05337812]\n",
      " [-0.01150181 -0.06389136 -0.06321312 ... -0.07172181 -0.03851101\n",
      "   0.02834268]]\n",
      "\n",
      "(784, 300)\n",
      "\n",
      "(300,)\n",
      "\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "#get_weight() / set_weights() 메서드를 사용해 접근할 수 있다.\n",
    "weights, biases = hidden1.get_weights()\n",
    "print(weights, end = \"\\n\\n\")\n",
    "print(weights.shape, end = \"\\n\\n\")\n",
    "print(biases.shape, end = \"\\n\\n\")\n",
    "print(biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 모델 컴파일\n",
    " - 레이블이 정수 하나로 이루어져 있고, 클래스가 배타적이므로 sparse_categorical_crossentropy 손실을 사용\n",
    " - 샘플마다 클래스별 타킷 확률을 가지고 있다면 categorical_crossentropy 손실을 사용\n",
    " - 이진 분류를 수행한다면 출력층에 softmax 함수 대신 sigmoid 함수를 사용하고 binary_crossentropy를 사용\n",
    " - 옵티마이저에 sgd를 지정하면 기본 확률적 경사 하강법을 사용하여 모델을 훈련\n",
    " - 분류기이므로 훈련과 평가 시에 정확도를 측정하기 위해 accuracy로 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile() 메서드를 호출하여 사용할 손실 함수와 옵티마이저(Optimizer)를 지정\n",
    "model.compile(loss = \"sparse_categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 모델 훈련과 평가\n",
    " - 훈련 세트가 편중되어 있다면 class_weight 매개변수를 지정\n",
    " - 샘플별 가중치를 부여하고 싶다면 sample_weight 매개변수를 지정\n",
    " - history 객체에는 훈련 파라미터, 수행된 에포크 리스트가 포함. 에포크가 끝날 때마다 훈련 세트와 검증 세트에 대한 손실과 측정한 지표를 담은 딕셔너리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1719/1719 [==============================] - 1s 766us/step - loss: 0.7162 - accuracy: 0.7647 - val_loss: 0.5297 - val_accuracy: 0.8176\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 1s 679us/step - loss: 0.4871 - accuracy: 0.8303 - val_loss: 0.4374 - val_accuracy: 0.8500\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 1s 683us/step - loss: 0.4397 - accuracy: 0.8447 - val_loss: 0.5205 - val_accuracy: 0.8048\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 1s 685us/step - loss: 0.4125 - accuracy: 0.8554 - val_loss: 0.3969 - val_accuracy: 0.8642\n",
      "Epoch 5/30\n",
      "1719/1719 [==============================] - 1s 685us/step - loss: 0.3942 - accuracy: 0.8615 - val_loss: 0.3792 - val_accuracy: 0.8686\n",
      "Epoch 6/30\n",
      "1719/1719 [==============================] - 1s 688us/step - loss: 0.3759 - accuracy: 0.8669 - val_loss: 0.3744 - val_accuracy: 0.8712\n",
      "Epoch 7/30\n",
      "1719/1719 [==============================] - 1s 683us/step - loss: 0.3636 - accuracy: 0.8717 - val_loss: 0.3643 - val_accuracy: 0.8758\n",
      "Epoch 8/30\n",
      "1719/1719 [==============================] - 1s 700us/step - loss: 0.3526 - accuracy: 0.8749 - val_loss: 0.3958 - val_accuracy: 0.8588\n",
      "Epoch 9/30\n",
      "1719/1719 [==============================] - 1s 705us/step - loss: 0.3421 - accuracy: 0.8785 - val_loss: 0.3514 - val_accuracy: 0.8720\n",
      "Epoch 10/30\n",
      "1719/1719 [==============================] - 1s 704us/step - loss: 0.3331 - accuracy: 0.8814 - val_loss: 0.3540 - val_accuracy: 0.8758\n",
      "Epoch 11/30\n",
      "1719/1719 [==============================] - 1s 872us/step - loss: 0.3251 - accuracy: 0.8840 - val_loss: 0.3478 - val_accuracy: 0.8768\n",
      "Epoch 12/30\n",
      "1719/1719 [==============================] - 1s 793us/step - loss: 0.3162 - accuracy: 0.8861 - val_loss: 0.3349 - val_accuracy: 0.8810\n",
      "Epoch 13/30\n",
      "1719/1719 [==============================] - 1s 708us/step - loss: 0.3096 - accuracy: 0.8889 - val_loss: 0.3363 - val_accuracy: 0.8824\n",
      "Epoch 14/30\n",
      "1719/1719 [==============================] - 1s 694us/step - loss: 0.3033 - accuracy: 0.8910 - val_loss: 0.3548 - val_accuracy: 0.8682\n",
      "Epoch 15/30\n",
      "1719/1719 [==============================] - 1s 698us/step - loss: 0.2954 - accuracy: 0.8935 - val_loss: 0.3337 - val_accuracy: 0.8794\n",
      "Epoch 16/30\n",
      "1719/1719 [==============================] - 1s 695us/step - loss: 0.2908 - accuracy: 0.8956 - val_loss: 0.3116 - val_accuracy: 0.8880\n",
      "Epoch 17/30\n",
      "1719/1719 [==============================] - 1s 697us/step - loss: 0.2853 - accuracy: 0.8968 - val_loss: 0.3511 - val_accuracy: 0.8754\n",
      "Epoch 18/30\n",
      "1719/1719 [==============================] - 1s 695us/step - loss: 0.2791 - accuracy: 0.8990 - val_loss: 0.3181 - val_accuracy: 0.8870\n",
      "Epoch 19/30\n",
      "1719/1719 [==============================] - 1s 696us/step - loss: 0.2745 - accuracy: 0.9007 - val_loss: 0.3148 - val_accuracy: 0.8870\n",
      "Epoch 20/30\n",
      "1719/1719 [==============================] - 1s 690us/step - loss: 0.2690 - accuracy: 0.9036 - val_loss: 0.3320 - val_accuracy: 0.8794\n",
      "Epoch 21/30\n",
      "1719/1719 [==============================] - 1s 688us/step - loss: 0.2642 - accuracy: 0.9045 - val_loss: 0.3053 - val_accuracy: 0.8932\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 1s 694us/step - loss: 0.2592 - accuracy: 0.9059 - val_loss: 0.2994 - val_accuracy: 0.8916\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 1s 696us/step - loss: 0.2552 - accuracy: 0.9077 - val_loss: 0.3038 - val_accuracy: 0.8894\n",
      "Epoch 24/30\n",
      "1719/1719 [==============================] - 1s 687us/step - loss: 0.2506 - accuracy: 0.9086 - val_loss: 0.3081 - val_accuracy: 0.8874\n",
      "Epoch 25/30\n",
      "1719/1719 [==============================] - 1s 696us/step - loss: 0.2464 - accuracy: 0.9111 - val_loss: 0.3028 - val_accuracy: 0.8910\n",
      "Epoch 26/30\n",
      "1719/1719 [==============================] - 1s 700us/step - loss: 0.2422 - accuracy: 0.9122 - val_loss: 0.3109 - val_accuracy: 0.8902\n",
      "Epoch 27/30\n",
      "1719/1719 [==============================] - 1s 709us/step - loss: 0.2388 - accuracy: 0.9140 - val_loss: 0.2970 - val_accuracy: 0.8948\n",
      "Epoch 28/30\n",
      "1719/1719 [==============================] - 1s 705us/step - loss: 0.2354 - accuracy: 0.9149 - val_loss: 0.3048 - val_accuracy: 0.8886\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 1s 703us/step - loss: 0.2308 - accuracy: 0.9175 - val_loss: 0.3083 - val_accuracy: 0.8904\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 1s 709us/step - loss: 0.2275 - accuracy: 0.9187 - val_loss: 0.3081 - val_accuracy: 0.8904\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs = 30, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'verbose': 1, 'epochs': 30, 'steps': 1719}\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]\n",
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "print(history.params)\n",
    "print(history.epoch)\n",
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Pandas를 이용한 학습 곡선 출력\n",
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0 ,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 모델 성능에 만족스럽지 않으면 처음으로 되돌아가서 하이퍼 파라미터를 튜닝해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 478us/step - loss: 0.3401 - accuracy: 0.8796\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.34010881185531616, 0.8795999884605408]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluate() 메서드를 통한 테스트 세트로 모델을 평가하여 일반화 오차를 추정\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 모델을 사용해 예측을 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.01, 0.  , 0.98],\n",
       "       [0.  , 0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#0~9까지 클래스마다 각각의 확률을 모델이 추정\n",
    "X_new = X_test[:3]\n",
    "y_proba = model.predict(X_new)\n",
    "y_proba.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-66-a058193f985f>:2: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#가장 높은 확률을 가진 클래스에만 관심이 있다면 predict_classes()메서드를 사용\n",
    "y_pred = model.predict_classes(X_new)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ankle boot', 'Pullover', 'Trouser'], dtype='<U11')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(class_names)[y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 518.4x172.8 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(7.2, 2.4))\n",
    "for index, image in enumerate(X_new):\n",
    "    plt.subplot(1, 3, index + 1)\n",
    "    plt.imshow(image, cmap=\"binary\", interpolation=\"nearest\")\n",
    "    plt.axis('off')\n",
    "    plt.title(class_names[y_test[index]], fontsize=12)\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.2.3 시퀀셜 API를 사용하여 회귀용 다층 퍼셉트론 만들기\n",
    "\n",
    "* 캘리포니아 주택 데이터셋을 로드하여 나누고 스케일 바꾸기\n",
    "* 출력층이 활성화 함수가 없는 하나의 뉴런을 가지고, 손실 함수로 평균 제곱 오차를 사용한다\n",
    "* 이 데이터셋에는 잡음이 많기 때문에 과대적합을 막는 용도로 뉴런 수가 적은 은닉층 하나만 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target, random_state = 42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state = 42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 0s 591us/step - loss: 0.7294 - val_loss: 15.9921\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 406us/step - loss: 0.6180 - val_loss: 9.6009\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 409us/step - loss: 0.5292 - val_loss: 0.4534\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 414us/step - loss: 0.3957 - val_loss: 0.3639\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 410us/step - loss: 0.3849 - val_loss: 0.3605\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 420us/step - loss: 0.3776 - val_loss: 0.3825\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 409us/step - loss: 0.3765 - val_loss: 0.3767\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 423us/step - loss: 0.3689 - val_loss: 0.3864\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 415us/step - loss: 0.3649 - val_loss: 0.4068\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 415us/step - loss: 0.3633 - val_loss: 0.3810\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 415us/step - loss: 0.3598 - val_loss: 0.3596\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 419us/step - loss: 0.3585 - val_loss: 0.3756\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 420us/step - loss: 0.3549 - val_loss: 0.3618\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 418us/step - loss: 0.3520 - val_loss: 0.3504\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 423us/step - loss: 0.3546 - val_loss: 0.3635\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 417us/step - loss: 0.3494 - val_loss: 0.3388\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 418us/step - loss: 0.3476 - val_loss: 0.3475\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 415us/step - loss: 0.3467 - val_loss: 0.3460\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 418us/step - loss: 0.3551 - val_loss: 0.3390\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 415us/step - loss: 0.3451 - val_loss: 0.3897\n",
      "162/162 [==============================] - 0s 289us/step - loss: 0.3437\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation = \"relu\", input_shape = X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss = \"mean_squared_error\", optimizer = \"sgd\")\n",
    "history = model.fit(X_train, y_train, epochs = 20, validation_data = (X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "X_new = X_test[:3]\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pd.DataFrame(history.history))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7122221],\n",
       "       [1.668096 ],\n",
       "       [4.128047 ]], dtype=float32)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 시퀀셜 API는 사용하기 쉽지만 입력과 추력이 여러 개거나 더 복잡한 네트워크 토폴로지를 갖는 신경망을 만들어야 할때가 있다.\n",
    "* 이를 위해 케라스는 함수형(Functional) API를 제공한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.2.4 함수형 API를 사용해 복잡한 모델 만들기\n",
    "\n",
    "* 2016년 헝쯔 청의 논문으로 소개된 순차적이지 않은 와이드 & 딥(Wide & Deep) 신경망\n",
    "* 이 신경망은 입력의 일부 또는 전체가 출력층에 바로 연결된다.\n",
    "* 이 구조는 신경망이 복잡한 패턴과 간단한 규칙을 모두 학습할 수 있다.\n",
    " 1. Input 객체 만들기 / Input 객체는 shape, dtype을 포함하여 모델의 입력을 정의\n",
    " 2. 30개의 뉴런과 ReLU 활성화 함수를 가진 Dense층 생성 / 케라스에 층이 연결될 방법을 알려줌\n",
    " 3. 두 번째 은닉층을 만들고 함수처럼 호출 / 첫 번째 층의 출력을 전달\n",
    " 4. Concatenate층을 만들고 함수처럼 호출하여 두 번재 은닉층의 출력과 입력을 연결\n",
    " 5. 하나의 뉴런과 활성화 함수가 없는 출력층을 만들고 Concatenate층이 만든 결과를 사용해 호출\n",
    " 6. 마지막으로 사용할 입력과 출력을 지정하여 케라스 Model을 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = keras.layers.Input(shape = X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(30, activation = \"relu\")(input_)\n",
    "hidden2 = keras.layers.Dense(30, activation = \"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.models.Model(inputs = [input_], outputs= [output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 8)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 30)           270         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 30)           930         dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 38)           0           input_2[0][0]                    \n",
      "                                                                 dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 1)            39          concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,239\n",
      "Trainable params: 1,239\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 0s 670us/step - loss: 1.6920 - val_loss: 0.8798\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 473us/step - loss: 0.6836 - val_loss: 0.6420\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 457us/step - loss: 0.6265 - val_loss: 0.5891\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 448us/step - loss: 0.5877 - val_loss: 0.5455\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 453us/step - loss: 0.5566 - val_loss: 0.5409\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 457us/step - loss: 0.5312 - val_loss: 0.4903\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 456us/step - loss: 0.5108 - val_loss: 0.4728\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 468us/step - loss: 0.4952 - val_loss: 0.5017\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 454us/step - loss: 0.4802 - val_loss: 0.4511\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 453us/step - loss: 0.4685 - val_loss: 0.4330\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 448us/step - loss: 0.4590 - val_loss: 0.4991\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 451us/step - loss: 0.4502 - val_loss: 0.4179\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 445us/step - loss: 0.4433 - val_loss: 0.4409\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 451us/step - loss: 0.4363 - val_loss: 0.4239\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 442us/step - loss: 0.4306 - val_loss: 0.4480\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 445us/step - loss: 0.4253 - val_loss: 0.4113\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 450us/step - loss: 0.4213 - val_loss: 0.4454\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 460us/step - loss: 0.4168 - val_loss: 0.4538\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 462us/step - loss: 0.4126 - val_loss: 0.4084\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 459us/step - loss: 0.4096 - val_loss: 0.4581\n",
      "162/162 [==============================] - 0s 289us/step - loss: 0.4007\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 일부 특성은 짧은 경로로 전달하고, 다른 특성들은 깊은 경로로 전달하고 싶다면?\n",
    " - 여러 입력을 사용한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"output\")(concat)\n",
    "model = keras.models.Model(inputs=[input_A, input_B], outputs=[output])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - 모델을 만들 때 inputs = [input_A, input_B]와 같이 지정\n",
    " - fit() 메서드를 호출할 때 하나의 입력 행렬 X_train가 아닌 입력마나 하나씩의 튜플(X_train_A, X_train_B)을 전달\n",
    " - X_valid / evaluate() / predict() 에도 동일하게 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 0s 665us/step - loss: 2.1094 - val_loss: 1.0289\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 469us/step - loss: 0.7849 - val_loss: 0.6881\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 466us/step - loss: 0.6517 - val_loss: 0.6039\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 481us/step - loss: 0.5965 - val_loss: 0.5446\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 514us/step - loss: 0.5595 - val_loss: 0.5129\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 475us/step - loss: 0.5311 - val_loss: 0.4873\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 456us/step - loss: 0.5084 - val_loss: 0.4673\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 459us/step - loss: 0.4898 - val_loss: 0.4499\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 453us/step - loss: 0.4748 - val_loss: 0.4373\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 472us/step - loss: 0.4641 - val_loss: 0.4269\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 464us/step - loss: 0.4561 - val_loss: 0.4202\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 476us/step - loss: 0.4496 - val_loss: 0.4141\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 464us/step - loss: 0.4443 - val_loss: 0.4102\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 464us/step - loss: 0.4398 - val_loss: 0.4063\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 462us/step - loss: 0.4362 - val_loss: 0.4027\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 459us/step - loss: 0.4332 - val_loss: 0.4012\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 459us/step - loss: 0.4306 - val_loss: 0.3977\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 473us/step - loss: 0.4282 - val_loss: 0.3951\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 464us/step - loss: 0.4256 - val_loss: 0.3950\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 458us/step - loss: 0.4240 - val_loss: 0.3968\n",
      "162/162 [==============================] - 0s 308us/step - loss: 0.4183\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "\n",
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n",
    "\n",
    "history = model.fit((X_train_A, X_train_B), y_train, epochs=20,\n",
    "                    validation_data=((X_valid_A, X_valid_B), y_valid))\n",
    "mse_test = model.evaluate((X_test_A, X_test_B), y_test)\n",
    "y_pred = model.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 여러 개의 출력이 필요한 경우\n",
    " - 회귀 작업과 분류 작업을 함께 하는 경우\n",
    " - 동일한 데이터에서 독립적인 여러 작업을 수행할 때\n",
    " - 규제 기법을 사용하는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"main_output\")(concat)\n",
    "aux_output = keras.layers.Dense(1, name=\"aux_output\")(hidden2)\n",
    "model = keras.Model(inputs = [input_A, input_B], outputs = [output, aux_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = [\"mse\", \"mse\"], loss_weights = [0.9, 0.1], optimizer = \"sgd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 0s 862us/step - loss: 0.9008 - main_output_loss: 0.7868 - aux_output_loss: 1.9275 - val_loss: 5.1884 - val_main_output_loss: 5.3132 - val_aux_output_loss: 4.0648\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 555us/step - loss: 0.5814 - main_output_loss: 0.5197 - aux_output_loss: 1.1365 - val_loss: 1.0598 - val_main_output_loss: 1.0076 - val_aux_output_loss: 1.5302\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 546us/step - loss: 0.4909 - main_output_loss: 0.4426 - aux_output_loss: 0.9259 - val_loss: 0.4891 - val_main_output_loss: 0.4450 - val_aux_output_loss: 0.8865\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 539us/step - loss: 0.4596 - main_output_loss: 0.4216 - aux_output_loss: 0.8012 - val_loss: 0.4692 - val_main_output_loss: 0.4334 - val_aux_output_loss: 0.7914\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 530us/step - loss: 0.4448 - main_output_loss: 0.4132 - aux_output_loss: 0.7292 - val_loss: 0.4513 - val_main_output_loss: 0.4217 - val_aux_output_loss: 0.7183\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 544us/step - loss: 0.4369 - main_output_loss: 0.4100 - aux_output_loss: 0.6790 - val_loss: 0.5499 - val_main_output_loss: 0.5349 - val_aux_output_loss: 0.6845\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 543us/step - loss: 0.4360 - main_output_loss: 0.4127 - aux_output_loss: 0.6457 - val_loss: 0.4340 - val_main_output_loss: 0.4124 - val_aux_output_loss: 0.6281\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 536us/step - loss: 0.4219 - main_output_loss: 0.3999 - aux_output_loss: 0.6195 - val_loss: 0.4224 - val_main_output_loss: 0.4030 - val_aux_output_loss: 0.5975\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 533us/step - loss: 0.4133 - main_output_loss: 0.3925 - aux_output_loss: 0.6006 - val_loss: 0.4200 - val_main_output_loss: 0.4029 - val_aux_output_loss: 0.5741\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 533us/step - loss: 0.4090 - main_output_loss: 0.3892 - aux_output_loss: 0.5874 - val_loss: 0.4228 - val_main_output_loss: 0.4074 - val_aux_output_loss: 0.5610\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 539us/step - loss: 0.4113 - main_output_loss: 0.3927 - aux_output_loss: 0.5785 - val_loss: 0.3965 - val_main_output_loss: 0.3775 - val_aux_output_loss: 0.5676\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 531us/step - loss: 0.4109 - main_output_loss: 0.3920 - aux_output_loss: 0.5810 - val_loss: 0.3904 - val_main_output_loss: 0.3729 - val_aux_output_loss: 0.5475\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 544us/step - loss: 0.4050 - main_output_loss: 0.3868 - aux_output_loss: 0.5689 - val_loss: 0.3842 - val_main_output_loss: 0.3671 - val_aux_output_loss: 0.5379\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 541us/step - loss: 0.3967 - main_output_loss: 0.3787 - aux_output_loss: 0.5595 - val_loss: 0.3774 - val_main_output_loss: 0.3599 - val_aux_output_loss: 0.5351\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 533us/step - loss: 0.3990 - main_output_loss: 0.3820 - aux_output_loss: 0.5513 - val_loss: 0.3794 - val_main_output_loss: 0.3621 - val_aux_output_loss: 0.5359\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 536us/step - loss: 0.3901 - main_output_loss: 0.3728 - aux_output_loss: 0.5457 - val_loss: 0.3753 - val_main_output_loss: 0.3577 - val_aux_output_loss: 0.5334\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 539us/step - loss: 0.3913 - main_output_loss: 0.3748 - aux_output_loss: 0.5394 - val_loss: 0.4622 - val_main_output_loss: 0.4384 - val_aux_output_loss: 0.6762\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 544us/step - loss: 0.3857 - main_output_loss: 0.3691 - aux_output_loss: 0.5353 - val_loss: 0.3625 - val_main_output_loss: 0.3445 - val_aux_output_loss: 0.5243\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 539us/step - loss: 0.3864 - main_output_loss: 0.3704 - aux_output_loss: 0.5300 - val_loss: 0.3686 - val_main_output_loss: 0.3513 - val_aux_output_loss: 0.5243\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 534us/step - loss: 0.3823 - main_output_loss: 0.3665 - aux_output_loss: 0.5240 - val_loss: 0.3685 - val_main_output_loss: 0.3506 - val_aux_output_loss: 0.5295\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([X_train_A, X_train_B], [y_train, y_train], epochs=20,\n",
    "                    validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 388us/step - loss: 0.3705 - main_output_loss: 0.3561 - aux_output_loss: 0.4995\n",
      "WARNING:tensorflow:5 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000218942653A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "total_loss, main_loss, aux_loss = model.evaluate(\n",
    "    [X_test_A, X_test_B], [y_test, y_test])\n",
    "y_pred_main, y_pred_aux = model.predict([X_new_A, X_new_B])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.2.5 서브클래싱 API로 동적 모델 만들기\n",
    "\n",
    "* 위와 같은 정적 API들은 장점도 많지만, 반복문을 포함하거나 다양한 크기를 다루어야 하는 조건문을 가지는 등 여러 가지 동적인 구조를 필요로 할 때도 있다.\n",
    "* 이런 경우 조금 더 명령형(Imperative) 프로그래밍 스타일이 필요할때 서브클래싱(Subclassing) API를 사용할 수 있다.\n",
    " - Model 클래스를 상속한 다음 생성자 안에서 필요한 층을 만든다.\n",
    " - 그다음 call()메서드 안에 수행하려는 연산을 기술한다.\n",
    " - 이전에 했던 것처럼 이 인스턴스를 사용해 모델 컴파일, 훈련, 평가, 예측을 수행할 수 있다.\n",
    " \n",
    " \n",
    "* 유연성이 높아진 API라 할 수 있다.\n",
    "* 유연성이 높아지면 그에 따른 비용이 발생한다. 모델 구조가 call() 메서드 안에 숨겨져 있기 때문에 케라스가 쉽게 이를 분석할 수 없다. 즉 모델을 저장 또는 복사할 수 없다.\n",
    "* 케라스가 타입과 크기를 미리 확인할 수 없다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeepModel(keras.models.Model):\n",
    "    def __init__(self, units=30, activation=\"relu\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
    "        self.hidden2 = keras.layers.Dense(units, activation=activation)\n",
    "        self.main_output = keras.layers.Dense(1)\n",
    "        self.aux_output = keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        input_A, input_B = inputs\n",
    "        hidden1 = self.hidden1(input_B)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = keras.layers.concatenate([input_A, hidden2])\n",
    "        main_output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "        return main_output, aux_output\n",
    "\n",
    "model = WideAndDeepModel(30, activation=\"relu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 2.4779 - output_1_loss: 2.2495 - output_2_loss: 4.5334 - val_loss: 2.3091 - val_output_1_loss: 2.1650 - val_output_2_loss: 3.6064\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 0s 541us/step - loss: 1.0367 - output_1_loss: 0.8524 - output_2_loss: 2.6948 - val_loss: 1.1543 - val_output_1_loss: 0.9436 - val_output_2_loss: 3.0508\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 0s 541us/step - loss: 0.8111 - output_1_loss: 0.6882 - output_2_loss: 1.9164 - val_loss: 0.8972 - val_output_1_loss: 0.6708 - val_output_2_loss: 2.9343\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 0s 541us/step - loss: 0.7203 - output_1_loss: 0.6216 - output_2_loss: 1.6083 - val_loss: 0.8175 - val_output_1_loss: 0.5908 - val_output_2_loss: 2.8576\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 0s 533us/step - loss: 0.6718 - output_1_loss: 0.5819 - output_2_loss: 1.4805 - val_loss: 0.7650 - val_output_1_loss: 0.5440 - val_output_2_loss: 2.7535\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 0s 535us/step - loss: 0.6404 - output_1_loss: 0.5542 - output_2_loss: 1.4164 - val_loss: 0.7292 - val_output_1_loss: 0.5186 - val_output_2_loss: 2.6250\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 0s 535us/step - loss: 0.6174 - output_1_loss: 0.5332 - output_2_loss: 1.3752 - val_loss: 0.6941 - val_output_1_loss: 0.4962 - val_output_2_loss: 2.4752\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 0s 542us/step - loss: 0.5992 - output_1_loss: 0.5169 - output_2_loss: 1.3405 - val_loss: 0.6642 - val_output_1_loss: 0.4795 - val_output_2_loss: 2.3269\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 0s 546us/step - loss: 0.5837 - output_1_loss: 0.5029 - output_2_loss: 1.3106 - val_loss: 0.6393 - val_output_1_loss: 0.4672 - val_output_2_loss: 2.1884\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 0s 536us/step - loss: 0.5704 - output_1_loss: 0.4912 - output_2_loss: 1.2830 - val_loss: 0.6155 - val_output_1_loss: 0.4558 - val_output_2_loss: 2.0534\n",
      "162/162 [==============================] - 0s 375us/step - loss: 0.5569 - output_1_loss: 0.4791 - output_2_loss: 1.2571\n",
      "WARNING:tensorflow:6 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000218941E8430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", loss_weights=[0.9, 0.1], optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "history = model.fit((X_train_A, X_train_B), (y_train, y_train), epochs=10,\n",
    "                    validation_data=((X_valid_A, X_valid_B), (y_valid, y_valid)))\n",
    "total_loss, main_loss, aux_loss = model.evaluate((X_test_A, X_test_B), (y_test, y_test))\n",
    "y_pred_main, y_pred_aux = model.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.2.6 모델 저장과 복원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  1/363 [..............................] - ETA: 0s - loss: 5.8337WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "363/363 [==============================] - 0s 626us/step - loss: 1.6890 - val_loss: 0.9207\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 0s 441us/step - loss: 0.7894 - val_loss: 0.7181\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 0s 440us/step - loss: 0.6738 - val_loss: 0.6226\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 0s 442us/step - loss: 0.6047 - val_loss: 0.5419\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 0s 437us/step - loss: 0.5539 - val_loss: 0.5061\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 0s 442us/step - loss: 0.5149 - val_loss: 0.4734\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 0s 453us/step - loss: 0.4849 - val_loss: 0.4571\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 0s 462us/step - loss: 0.4620 - val_loss: 0.4476\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 0s 470us/step - loss: 0.4451 - val_loss: 0.4324\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 0s 460us/step - loss: 0.4322 - val_loss: 0.4456\n",
      "162/162 [==============================] - 0s 296us/step - loss: 0.4239\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:7 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002188A32E940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.94346404],\n",
       "       [1.6388651 ],\n",
       "       [3.440311  ]], dtype=float32)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.2.7 콜백 사용하기\n",
    "\n",
    "* 훈련 도중 일정 간격으로 체크포인트를 저장할 수 있다.\n",
    "* fit()메서드의 callbacks 매개변수를 사용하여 케라스가 훈련의 시작이나 끝에 호출할 객체 리스트를 지정할 수 있다.\n",
    "* 에포크의 시작이나 끝, 각 배치 처리 전후에 호출할 수도 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 0s 637us/step - loss: 1.8866 - val_loss: 0.7126\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 0s 456us/step - loss: 0.6577 - val_loss: 0.6880\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 0s 459us/step - loss: 0.5934 - val_loss: 0.5803\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 0s 453us/step - loss: 0.5557 - val_loss: 0.5166\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 0s 451us/step - loss: 0.5272 - val_loss: 0.4895\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 0s 443us/step - loss: 0.5033 - val_loss: 0.4951\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 0s 453us/step - loss: 0.4854 - val_loss: 0.4861\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 0s 464us/step - loss: 0.4709 - val_loss: 0.4554\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 0s 453us/step - loss: 0.4578 - val_loss: 0.4413\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 0s 453us/step - loss: 0.4474 - val_loss: 0.4379\n",
      "162/162 [==============================] - 0s 289us/step - loss: 0.4382\n"
     ]
    }
   ],
   "source": [
    "#ModelCheckpoint()는 훈련하는 동안 일정한 간격으로 모델의 체크포인트를 저장\n",
    "#save_best_only = True로 체크포인트 지정 / 최상의 점수를 낸 모델 저장\n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\", save_best_only=True)\n",
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb])\n",
    "model = keras.models.load_model(\"my_keras_model.h5\") # 최상의 모델로 롤백\n",
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 0s 643us/step - loss: 0.4393 - val_loss: 0.4110\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 440us/step - loss: 0.4315 - val_loss: 0.4266\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 448us/step - loss: 0.4259 - val_loss: 0.3996\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 449us/step - loss: 0.4201 - val_loss: 0.3939\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 459us/step - loss: 0.4154 - val_loss: 0.3889\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 457us/step - loss: 0.4111 - val_loss: 0.3866\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 461us/step - loss: 0.4074 - val_loss: 0.3860\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 451us/step - loss: 0.4040 - val_loss: 0.3793\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 459us/step - loss: 0.4008 - val_loss: 0.3746\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 459us/step - loss: 0.3976 - val_loss: 0.3723\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 465us/step - loss: 0.3950 - val_loss: 0.3697\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 466us/step - loss: 0.3923 - val_loss: 0.3669\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 459us/step - loss: 0.3897 - val_loss: 0.3661\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 459us/step - loss: 0.3874 - val_loss: 0.3631\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 448us/step - loss: 0.3851 - val_loss: 0.3660\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 451us/step - loss: 0.3829 - val_loss: 0.3625\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 0s 456us/step - loss: 0.3810 - val_loss: 0.3592\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 0s 456us/step - loss: 0.3788 - val_loss: 0.3563\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 460us/step - loss: 0.3766 - val_loss: 0.3535\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 438us/step - loss: 0.3750 - val_loss: 0.3709\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 0s 457us/step - loss: 0.3732 - val_loss: 0.3512\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 427us/step - loss: 0.3715 - val_loss: 0.3699\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 0s 464us/step - loss: 0.3700 - val_loss: 0.3476\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 462us/step - loss: 0.3685 - val_loss: 0.3561\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 0s 451us/step - loss: 0.3671 - val_loss: 0.3527\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 473us/step - loss: 0.3658 - val_loss: 0.3700\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 0s 459us/step - loss: 0.3647 - val_loss: 0.3432\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 0s 437us/step - loss: 0.3635 - val_loss: 0.3592\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 0s 440us/step - loss: 0.3625 - val_loss: 0.3521\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 0s 432us/step - loss: 0.3613 - val_loss: 0.3626\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 0s 453us/step - loss: 0.3601 - val_loss: 0.3431\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 0s 448us/step - loss: 0.3589 - val_loss: 0.3765\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 0s 456us/step - loss: 0.3584 - val_loss: 0.3374\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 0s 437us/step - loss: 0.3572 - val_loss: 0.3407\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 0s 440us/step - loss: 0.3563 - val_loss: 0.3614\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 0s 451us/step - loss: 0.3555 - val_loss: 0.3348\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 0s 441us/step - loss: 0.3546 - val_loss: 0.3573\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 0s 438us/step - loss: 0.3538 - val_loss: 0.3367\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 0s 452us/step - loss: 0.3530 - val_loss: 0.3425\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 0s 434us/step - loss: 0.3523 - val_loss: 0.3369\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 0s 442us/step - loss: 0.3515 - val_loss: 0.3515\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 0s 440us/step - loss: 0.3511 - val_loss: 0.3426\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 0s 448us/step - loss: 0.3500 - val_loss: 0.3677\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 0s 445us/step - loss: 0.3496 - val_loss: 0.3564\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 0s 462us/step - loss: 0.3490 - val_loss: 0.3336\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 0s 451us/step - loss: 0.3481 - val_loss: 0.3457\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 0s 442us/step - loss: 0.3478 - val_loss: 0.3433\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 0s 440us/step - loss: 0.3471 - val_loss: 0.3659\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 0s 458us/step - loss: 0.3466 - val_loss: 0.3286\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 0s 464us/step - loss: 0.3460 - val_loss: 0.3268\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 0s 442us/step - loss: 0.3454 - val_loss: 0.3439\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 0s 459us/step - loss: 0.3449 - val_loss: 0.3263\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 0s 429us/step - loss: 0.3444 - val_loss: 0.3910\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 0s 442us/step - loss: 0.3439 - val_loss: 0.3275\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 0s 451us/step - loss: 0.3435 - val_loss: 0.3561\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 0s 461us/step - loss: 0.3430 - val_loss: 0.3237\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 0s 439us/step - loss: 0.3423 - val_loss: 0.3242\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 0s 452us/step - loss: 0.3419 - val_loss: 0.3765\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 0s 442us/step - loss: 0.3417 - val_loss: 0.3289\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 0s 448us/step - loss: 0.3410 - val_loss: 0.3502\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 0s 445us/step - loss: 0.3404 - val_loss: 0.3456\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 0s 431us/step - loss: 0.3402 - val_loss: 0.3445\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 0s 434us/step - loss: 0.3392 - val_loss: 0.3290\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 0s 470us/step - loss: 0.3393 - val_loss: 0.3217\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 0s 457us/step - loss: 0.3387 - val_loss: 0.3351\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 0s 448us/step - loss: 0.3383 - val_loss: 0.3232\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 0s 445us/step - loss: 0.3376 - val_loss: 0.3566\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 0s 459us/step - loss: 0.3374 - val_loss: 0.3257\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 0s 451us/step - loss: 0.3370 - val_loss: 0.3348\n",
      "Epoch 70/100\n",
      "363/363 [==============================] - 0s 445us/step - loss: 0.3365 - val_loss: 0.3560\n",
      "Epoch 71/100\n",
      "363/363 [==============================] - 0s 434us/step - loss: 0.3361 - val_loss: 0.3583\n",
      "Epoch 72/100\n",
      "363/363 [==============================] - 0s 426us/step - loss: 0.3357 - val_loss: 0.3287\n",
      "Epoch 73/100\n",
      "363/363 [==============================] - 0s 448us/step - loss: 0.3351 - val_loss: 0.3203\n",
      "Epoch 74/100\n",
      "363/363 [==============================] - 0s 431us/step - loss: 0.3350 - val_loss: 0.3840\n",
      "Epoch 75/100\n",
      "363/363 [==============================] - 0s 453us/step - loss: 0.3347 - val_loss: 0.3233\n",
      "Epoch 76/100\n",
      "363/363 [==============================] - 0s 449us/step - loss: 0.3342 - val_loss: 0.3476\n",
      "Epoch 77/100\n",
      "363/363 [==============================] - 0s 438us/step - loss: 0.3338 - val_loss: 0.3407\n",
      "Epoch 78/100\n",
      "363/363 [==============================] - 0s 442us/step - loss: 0.3335 - val_loss: 0.3462\n",
      "Epoch 79/100\n",
      "363/363 [==============================] - 0s 448us/step - loss: 0.3332 - val_loss: 0.3347\n",
      "Epoch 80/100\n",
      "363/363 [==============================] - 0s 467us/step - loss: 0.3329 - val_loss: 0.3354\n",
      "Epoch 81/100\n",
      "363/363 [==============================] - 0s 448us/step - loss: 0.3324 - val_loss: 0.3274\n",
      "Epoch 82/100\n",
      "363/363 [==============================] - 0s 456us/step - loss: 0.3320 - val_loss: 0.3167\n",
      "Epoch 83/100\n",
      "363/363 [==============================] - 0s 444us/step - loss: 0.3317 - val_loss: 0.3280\n",
      "Epoch 84/100\n",
      "363/363 [==============================] - 0s 448us/step - loss: 0.3312 - val_loss: 0.3634\n",
      "Epoch 85/100\n",
      "363/363 [==============================] - 0s 453us/step - loss: 0.3310 - val_loss: 0.3176\n",
      "Epoch 86/100\n",
      "363/363 [==============================] - 0s 460us/step - loss: 0.3308 - val_loss: 0.3156\n",
      "Epoch 87/100\n",
      "363/363 [==============================] - 0s 459us/step - loss: 0.3305 - val_loss: 0.3529\n",
      "Epoch 88/100\n",
      "363/363 [==============================] - 0s 453us/step - loss: 0.3299 - val_loss: 0.3258\n",
      "Epoch 89/100\n",
      "363/363 [==============================] - 0s 448us/step - loss: 0.3294 - val_loss: 0.3630\n",
      "Epoch 90/100\n",
      "363/363 [==============================] - 0s 453us/step - loss: 0.3296 - val_loss: 0.3376\n",
      "Epoch 91/100\n",
      "363/363 [==============================] - 0s 451us/step - loss: 0.3291 - val_loss: 0.3211\n",
      "Epoch 92/100\n",
      "363/363 [==============================] - 0s 459us/step - loss: 0.3287 - val_loss: 0.3456\n",
      "Epoch 93/100\n",
      "363/363 [==============================] - 0s 459us/step - loss: 0.3285 - val_loss: 0.3158\n",
      "Epoch 94/100\n",
      "363/363 [==============================] - 0s 455us/step - loss: 0.3281 - val_loss: 0.3409\n",
      "Epoch 95/100\n",
      "363/363 [==============================] - 0s 465us/step - loss: 0.3276 - val_loss: 0.3379\n",
      "Epoch 96/100\n",
      "363/363 [==============================] - 0s 456us/step - loss: 0.3273 - val_loss: 0.3213\n",
      "162/162 [==============================] - 0s 296us/step - loss: 0.3310\n"
     ]
    }
   ],
   "source": [
    "#EarlyStopping 콜백을 통한 조기 종료\n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,\n",
    "                                                  restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, epochs=100,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, early_stopping_cb])\n",
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#더 많은 제어를 위해 사용자 정의 콜백을 만들 수 있다.\n",
    "#예시로 훈련하는 동안 검증 손실과 훈련 손실의 비율을 출력\n",
    "class PrintValTrainRatioCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        print(\"\\nval/train: {:.2f}\".format(logs[\"val_loss\"] / logs[\"loss\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/363 [=======================>......] - ETA: 0s - loss: 0.3328\n",
      "val/train: 1.08\n",
      "363/363 [==============================] - 0s 520us/step - loss: 0.3302 - val_loss: 0.3556\n"
     ]
    }
   ],
   "source": [
    "val_train_ratio_cb = PrintValTrainRatioCallback()\n",
    "history = model.fit(X_train, y_train, epochs=1,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[val_train_ratio_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.2.8 텐서보드를 사용해 시각화하기\n",
    "* 훈련하는 동안 학습 곡선을 그리거나 여러 실행 간의 학습 곡선을 비교하고 계산 그래프 시각화와 훈련 통계 분석을 수행할 수 있다.\n",
    "* 모델이 생성한 이미지를 확인하거나 3D에 투영된 복잡한 다차원 데이터를 시각화하고 자동으로 클러스터링을 해주는 등 많은 기능을 제공한다.\n",
    "* 텐서보드를 사용하려면 프로그램을 수정하여 이벤트 파일이라는 특별한 이진 로그 파일에 시각화하려는 데이터를 출력해야 한다. 각각의 이진 데이터 레코드를 서머리(Summary)라고 부른다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.\\\\my_logs\\\\run_2020_10_10-22_09_42'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#텐서보드 로그를 위해 사용할 루트 로그 디렉토리 정의\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir()\n",
    "run_logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])    \n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  1/363 [..............................] - ETA: 0s - loss: 7.8215WARNING:tensorflow:From C:\\Users\\uoo1325\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "  2/363 [..............................] - ETA: 14s - loss: 7.0195WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0030s vs `on_train_batch_begin` time: 0.0060s). Check your callbacks.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0030s vs `on_train_batch_end` time: 0.0691s). Check your callbacks.\n",
      "363/363 [==============================] - 0s 916us/step - loss: 1.8866 - val_loss: 0.7126\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 0s 479us/step - loss: 0.6577 - val_loss: 0.6880\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 0s 470us/step - loss: 0.5934 - val_loss: 0.5803\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 0s 489us/step - loss: 0.5557 - val_loss: 0.5166\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 0s 624us/step - loss: 0.5272 - val_loss: 0.4895\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 0s 486us/step - loss: 0.5033 - val_loss: 0.4951\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 0s 478us/step - loss: 0.4854 - val_loss: 0.4861\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 0s 512us/step - loss: 0.4709 - val_loss: 0.4554\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 0s 486us/step - loss: 0.4578 - val_loss: 0.4413\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 0s 504us/step - loss: 0.4474 - val_loss: 0.4379\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 0s 489us/step - loss: 0.4393 - val_loss: 0.4396\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 0s 622us/step - loss: 0.4318 - val_loss: 0.4507\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 0s 470us/step - loss: 0.4261 - val_loss: 0.3997\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 0s 473us/step - loss: 0.4202 - val_loss: 0.3956\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 0s 470us/step - loss: 0.4155 - val_loss: 0.3916\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 0s 448us/step - loss: 0.4112 - val_loss: 0.3937\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 0s 454us/step - loss: 0.4077 - val_loss: 0.3809\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 0s 532us/step - loss: 0.4040 - val_loss: 0.3793\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 0s 473us/step - loss: 0.4004 - val_loss: 0.3850\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 0s 496us/step - loss: 0.3980 - val_loss: 0.3809\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 0s 644us/step - loss: 0.3949 - val_loss: 0.3701\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 0s 519us/step - loss: 0.3924 - val_loss: 0.3781\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 0s 530us/step - loss: 0.3898 - val_loss: 0.3650\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 0s 512us/step - loss: 0.3874 - val_loss: 0.3655\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 0s 462us/step - loss: 0.3851 - val_loss: 0.3611\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 0s 456us/step - loss: 0.3829 - val_loss: 0.3626\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 0s 467us/step - loss: 0.3809 - val_loss: 0.3564\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 0s 467us/step - loss: 0.3788 - val_loss: 0.3579\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 0s 456us/step - loss: 0.3769 - val_loss: 0.3561\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 0s 460us/step - loss: 0.3750 - val_loss: 0.3548\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 1588), started 0:01:50 ago. (Use '!kill 1588' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-576c504223355020\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-576c504223355020\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./my_logs --port=6006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10.3 신경망 하이퍼 파라미터 튜닝하기\n",
    "\n",
    "* 아주 복잡한 네트워크 구조에서뿐만 아니라 간단한 다층 퍼셉트론에서도 층의 개수, 층마다 있는 뉴런의 개수, 각 층에서 사용하는 활성화 함수, 가중치 초기화 전략 등 많은 것을 바꿀 수 있다.\n",
    "* 문제 해결에서 최적인지 확인하기 위해서는 많은 하이퍼 파라미터 조합을 시도해보고, 검증 세트에서 가장 좋은 점수를 내는지 확인하는 것이다.\n",
    "* GridSearchCV 나 RandomizedSerachCV 를 사용해 하이퍼파라미터 공간을 탐색할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#입력 크기, 은닉층 개수, 뉴런 개수로 단변량 회귀를 위한 간단한 Sequentiaol 모델\n",
    "#회귀 추정기처럼 이 객체를 사용할 수 있다 : fit()을 통한 훈련 / score()로 평가 / predict()로 예측\n",
    "def build_model(n_hidden = 1, n_neurons = 30, learning_rate = 3e-3, input_shape = [8]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape = input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation = \"relu\"))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.SGD(lr = learning_rate)\n",
    "    model.compile(loss = \"mse\", optimizer = optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 0s 618us/step - loss: 1.1199 - val_loss: 10.5492\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 437us/step - loss: 0.6678 - val_loss: 0.5672\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 448us/step - loss: 0.5200 - val_loss: 0.4875\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 426us/step - loss: 0.4855 - val_loss: 0.4654\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 442us/step - loss: 0.4632 - val_loss: 0.4563\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 464us/step - loss: 0.4478 - val_loss: 0.4691\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 434us/step - loss: 0.4367 - val_loss: 0.4507\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 448us/step - loss: 0.4288 - val_loss: 0.4346\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 502us/step - loss: 0.4220 - val_loss: 0.4450\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 438us/step - loss: 0.4169 - val_loss: 0.4676\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 459us/step - loss: 0.4133 - val_loss: 0.4191\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 475us/step - loss: 0.4093 - val_loss: 0.4730\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 429us/step - loss: 0.4062 - val_loss: 0.4531\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 473us/step - loss: 0.4034 - val_loss: 0.4157\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 441us/step - loss: 0.4005 - val_loss: 0.4239\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 453us/step - loss: 0.3979 - val_loss: 0.4113\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 0s 453us/step - loss: 0.3955 - val_loss: 0.4587\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 0s 490us/step - loss: 0.3939 - val_loss: 0.4396\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 428us/step - loss: 0.3913 - val_loss: 0.4269\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 470us/step - loss: 0.3900 - val_loss: 0.4792\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 0s 448us/step - loss: 0.3881 - val_loss: 0.4489\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 440us/step - loss: 0.3865 - val_loss: 0.4685\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 0s 451us/step - loss: 0.3848 - val_loss: 0.3778\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 470us/step - loss: 0.3830 - val_loss: 0.4161\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 0s 450us/step - loss: 0.3814 - val_loss: 0.4650\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 451us/step - loss: 0.3804 - val_loss: 0.4595\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 0s 448us/step - loss: 0.3796 - val_loss: 0.3705\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 0s 455us/step - loss: 0.3782 - val_loss: 0.4312\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 0s 461us/step - loss: 0.3770 - val_loss: 0.3977\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 0s 445us/step - loss: 0.3756 - val_loss: 0.4618\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 0s 442us/step - loss: 0.3742 - val_loss: 0.4339\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 0s 443us/step - loss: 0.3730 - val_loss: 0.4634\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 0s 456us/step - loss: 0.3730 - val_loss: 0.3736\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 0s 420us/step - loss: 0.3711 - val_loss: 0.3775\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 0s 466us/step - loss: 0.3705 - val_loss: 0.4735\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 0s 459us/step - loss: 0.3697 - val_loss: 0.3513\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 0s 435us/step - loss: 0.3685 - val_loss: 0.4120\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 0s 466us/step - loss: 0.3677 - val_loss: 0.3616\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 0s 467us/step - loss: 0.3668 - val_loss: 0.3634\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 0s 440us/step - loss: 0.3656 - val_loss: 0.4097\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 0s 448us/step - loss: 0.3655 - val_loss: 0.4119\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 0s 473us/step - loss: 0.3646 - val_loss: 0.4322\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 0s 431us/step - loss: 0.3633 - val_loss: 0.4297\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 0s 445us/step - loss: 0.3622 - val_loss: 0.4451\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 0s 440us/step - loss: 0.3622 - val_loss: 0.3515\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 0s 420us/step - loss: 0.3603 - val_loss: 0.3710\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2188f4a1e20>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_reg.fit(X_train, y_train, epochs=100,\n",
    "              validation_data=(X_valid, y_valid),\n",
    "              callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 수백 개의 모델을 훈련하고 검증 세트에서 최상의 모델을 선택해야 한다.\n",
    "* 하이퍼 파라미터가 많으므로 그리드 탐색보다 랜덤 탐색을 사용하는 것이 좋다.\n",
    "* 은닉층 개수, 뉴런 개수, 학습률을 사용해 하이퍼 파라미터 탐색을 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 698us/step - loss: 3.8537 - val_loss: 1.5221\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 462us/step - loss: 1.1080 - val_loss: 0.7390\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 453us/step - loss: 0.6773 - val_loss: 0.6179\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.5898 - val_loss: 0.5781\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 453us/step - loss: 0.5680 - val_loss: 0.5662\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 457us/step - loss: 0.5576 - val_loss: 0.7680\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.5557 - val_loss: 0.7141\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.5519 - val_loss: 0.7329\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.5511 - val_loss: 0.5563\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 457us/step - loss: 0.5447 - val_loss: 0.7484\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 457us/step - loss: 0.5445 - val_loss: 0.7628\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 452us/step - loss: 0.5448 - val_loss: 0.5294\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 460us/step - loss: 0.5378 - val_loss: 0.8131\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 457us/step - loss: 0.5390 - val_loss: 0.8672\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 541us/step - loss: 0.5413 - val_loss: 0.5808\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 456us/step - loss: 0.5355 - val_loss: 0.7172\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 455us/step - loss: 0.5358 - val_loss: 0.7357\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 460us/step - loss: 0.5341 - val_loss: 0.8131\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 453us/step - loss: 0.5339 - val_loss: 0.8377\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 453us/step - loss: 0.5338 - val_loss: 0.8153\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 463us/step - loss: 0.5357 - val_loss: 0.5607\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 457us/step - loss: 0.5298 - val_loss: 0.7599\n",
      "121/121 [==============================] - 0s 297us/step - loss: 0.5315\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 713us/step - loss: 3.7034 - val_loss: 1.9653\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 472us/step - loss: 1.2683 - val_loss: 0.9443\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.8153 - val_loss: 1.6347\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.7012 - val_loss: 3.0315\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 455us/step - loss: 0.6572 - val_loss: 4.7697\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 457us/step - loss: 0.6312 - val_loss: 6.6540\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.6118 - val_loss: 8.5159\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.5961 - val_loss: 10.3407\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.5829 - val_loss: 11.9862\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 453us/step - loss: 0.5718 - val_loss: 13.3601\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 470us/step - loss: 0.5623 - val_loss: 14.7569\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 454us/step - loss: 0.5540 - val_loss: 15.9887\n",
      "121/121 [==============================] - 0s 297us/step - loss: 0.9210\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 691us/step - loss: 4.4792 - val_loss: 1.9849\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 1.3695 - val_loss: 0.9936\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 462us/step - loss: 0.8255 - val_loss: 0.7556\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.7073 - val_loss: 0.9860\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 457us/step - loss: 0.6753 - val_loss: 0.6295\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.6555 - val_loss: 0.7115\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 462us/step - loss: 0.6410 - val_loss: 0.7291\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 457us/step - loss: 0.6275 - val_loss: 0.9777\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 453us/step - loss: 0.6214 - val_loss: 0.7306\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 457us/step - loss: 0.6092 - val_loss: 0.5714\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 462us/step - loss: 0.5987 - val_loss: 0.9070\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 462us/step - loss: 0.5966 - val_loss: 0.6215\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.5868 - val_loss: 0.5548\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 460us/step - loss: 0.5813 - val_loss: 0.6590\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 470us/step - loss: 0.5771 - val_loss: 0.5674\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 473us/step - loss: 0.5690 - val_loss: 0.7955\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 460us/step - loss: 0.5694 - val_loss: 0.5930\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 464us/step - loss: 0.5640 - val_loss: 0.5707\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 462us/step - loss: 0.5576 - val_loss: 0.8706\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 470us/step - loss: 0.5598 - val_loss: 0.6340\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 453us/step - loss: 0.5549 - val_loss: 0.6248\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.5521 - val_loss: 0.6561\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.5517 - val_loss: 0.5281\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 462us/step - loss: 0.5475 - val_loss: 0.5752\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.5467 - val_loss: 0.5525\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.5448 - val_loss: 0.5049\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.5389 - val_loss: 0.8527\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 453us/step - loss: 0.5450 - val_loss: 0.5948\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 452us/step - loss: 0.5387 - val_loss: 0.7663\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.5420 - val_loss: 0.6133\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.5371 - val_loss: 0.6934\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.5378 - val_loss: 0.7751\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 455us/step - loss: 0.5372 - val_loss: 0.7651\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 453us/step - loss: 0.5370 - val_loss: 0.8166\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.5367 - val_loss: 0.8052\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.5382 - val_loss: 0.5236\n",
      "121/121 [==============================] - 0s 313us/step - loss: 0.5353\n",
      "Epoch 1/100\n",
      "  1/242 [..............................] - ETA: 0s - loss: 7.2833WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_begin` time: 0.0010s). Check your callbacks.\n",
      "242/242 [==============================] - 0s 743us/step - loss: 1.5978 - val_loss: 60.0505\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 1.9300 - val_loss: 390.1751\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 458us/step - loss: 2.9429 - val_loss: 1259.1334\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 10.5033 - val_loss: 5669.0195\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 469us/step - loss: 34.3114 - val_loss: 20702.8242\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 429.7315 - val_loss: 80649.2031\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 470us/step - loss: 842.8453 - val_loss: 316747.0000\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 462us/step - loss: 6185.8271 - val_loss: 1251627.0000\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 464us/step - loss: 15484.0244 - val_loss: 4929565.5000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 108970.8828 - val_loss: 20496498.0000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 462us/step - loss: 273988.5312 - val_loss: 80333840.0000\n",
      "121/121 [==============================] - 0s 288us/step - loss: 213157.9688\n",
      "Epoch 1/100\n",
      "163/242 [===================>..........] - ETA: 0s - loss: 2.0779 WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "242/242 [==============================] - 0s 845us/step - loss: 1.6141 - val_loss: 1.7872\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 565us/step - loss: 0.5868 - val_loss: 11.2662\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 0.5383 - val_loss: 18.9178\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 540us/step - loss: 0.5204 - val_loss: 21.2665\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 511us/step - loss: 0.5115 - val_loss: 21.9737\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 507us/step - loss: 0.5074 - val_loss: 22.0820\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 468us/step - loss: 0.5054 - val_loss: 21.4425\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 453us/step - loss: 0.5036 - val_loss: 21.9275\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 453us/step - loss: 0.5021 - val_loss: 21.0180\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 457us/step - loss: 0.5024 - val_loss: 17.6997\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 453us/step - loss: 0.5026 - val_loss: 19.7417\n",
      "121/121 [==============================] - 0s 289us/step - loss: 0.9676\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 706us/step - loss: 1.5539 - val_loss: 35.7873\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 462us/step - loss: 0.7284 - val_loss: 28.2745\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 457us/step - loss: 0.9442 - val_loss: 186.3759\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 457us/step - loss: 4.5768 - val_loss: 400.0385\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 456us/step - loss: 1.8671 - val_loss: 1328.1525\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 462us/step - loss: 10.0501 - val_loss: 2223.9011\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 460us/step - loss: 13.9984 - val_loss: 4587.2720\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 468us/step - loss: 87.0850 - val_loss: 9145.5918\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 464us/step - loss: 89.1398 - val_loss: 17986.7852\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 464us/step - loss: 46.4621 - val_loss: 32427.3965\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 858.7828 - val_loss: 62063.0039\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 453us/step - loss: 378.4839 - val_loss: 118413.7578\n",
      "121/121 [==============================] - 0s 293us/step - loss: 128.8227\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 853us/step - loss: 2.5634 - val_loss: 2.2880\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 536us/step - loss: 0.9765 - val_loss: 1.1030\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.7920 - val_loss: 0.7880\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 530us/step - loss: 0.7277 - val_loss: 0.6919\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 546us/step - loss: 0.6891 - val_loss: 0.6481\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 0.6600 - val_loss: 0.6205\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 0.6348 - val_loss: 0.6037\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 540us/step - loss: 0.6130 - val_loss: 0.5760\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 602us/step - loss: 0.5932 - val_loss: 0.5572\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 0.5751 - val_loss: 0.5401\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 536us/step - loss: 0.5589 - val_loss: 0.5271\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 528us/step - loss: 0.5444 - val_loss: 0.5093\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 548us/step - loss: 0.5305 - val_loss: 0.5005\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 548us/step - loss: 0.5184 - val_loss: 0.4851\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 535us/step - loss: 0.5073 - val_loss: 0.4738\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 540us/step - loss: 0.4969 - val_loss: 0.4646\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 538us/step - loss: 0.4879 - val_loss: 0.4563\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 542us/step - loss: 0.4794 - val_loss: 0.4479\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 536us/step - loss: 0.4716 - val_loss: 0.4427\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 0.4647 - val_loss: 0.4348\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.4584 - val_loss: 0.4349\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 532us/step - loss: 0.4524 - val_loss: 0.4263\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.4471 - val_loss: 0.4225\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 532us/step - loss: 0.4419 - val_loss: 0.4157\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 548us/step - loss: 0.4379 - val_loss: 0.4156\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 548us/step - loss: 0.4336 - val_loss: 0.4142\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 535us/step - loss: 0.4298 - val_loss: 0.4086\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 528us/step - loss: 0.4261 - val_loss: 0.4140\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 528us/step - loss: 0.4226 - val_loss: 0.4097\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 528us/step - loss: 0.4196 - val_loss: 0.4026\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 538us/step - loss: 0.4165 - val_loss: 0.3962\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 540us/step - loss: 0.4138 - val_loss: 0.3961\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 534us/step - loss: 0.4111 - val_loss: 0.4004\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 519us/step - loss: 0.4084 - val_loss: 0.4050\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 523us/step - loss: 0.4061 - val_loss: 0.3904\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 523us/step - loss: 0.4038 - val_loss: 0.3979\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 523us/step - loss: 0.4018 - val_loss: 0.3873\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 515us/step - loss: 0.3997 - val_loss: 0.3971\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 540us/step - loss: 0.3978 - val_loss: 0.3849\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 528us/step - loss: 0.3961 - val_loss: 0.3917\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 528us/step - loss: 0.3942 - val_loss: 0.3875\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 528us/step - loss: 0.3925 - val_loss: 0.3845\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 530us/step - loss: 0.3911 - val_loss: 0.3781\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 527us/step - loss: 0.3893 - val_loss: 0.3961\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 532us/step - loss: 0.3879 - val_loss: 0.3853\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 532us/step - loss: 0.3863 - val_loss: 0.3776\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 0.3850 - val_loss: 0.3895\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 523us/step - loss: 0.3836 - val_loss: 0.3770\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 532us/step - loss: 0.3822 - val_loss: 0.3770\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 523us/step - loss: 0.3809 - val_loss: 0.3848\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 532us/step - loss: 0.3796 - val_loss: 0.3771\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 528us/step - loss: 0.3787 - val_loss: 0.3765\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 528us/step - loss: 0.3774 - val_loss: 0.3775\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 548us/step - loss: 0.3762 - val_loss: 0.3666\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 542us/step - loss: 0.3748 - val_loss: 0.3779\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 528us/step - loss: 0.3741 - val_loss: 0.3733\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.3730 - val_loss: 0.3751\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.3718 - val_loss: 0.3832\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 540us/step - loss: 0.3709 - val_loss: 0.3668\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 528us/step - loss: 0.3698 - val_loss: 0.3694\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 528us/step - loss: 0.3691 - val_loss: 0.3751\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 540us/step - loss: 0.3681 - val_loss: 0.3832\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 536us/step - loss: 0.3673 - val_loss: 0.3718\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 535us/step - loss: 0.3664 - val_loss: 0.3870\n",
      "121/121 [==============================] - 0s 305us/step - loss: 0.3818\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 804us/step - loss: 2.8628 - val_loss: 2.7700\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 540us/step - loss: 1.0282 - val_loss: 3.1720\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 536us/step - loss: 0.7759 - val_loss: 2.3140\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 523us/step - loss: 0.6888 - val_loss: 1.6131\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 532us/step - loss: 0.6451 - val_loss: 1.1359\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 532us/step - loss: 0.6165 - val_loss: 0.8511\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 532us/step - loss: 0.5939 - val_loss: 0.6670\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 532us/step - loss: 0.5745 - val_loss: 0.5604\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 523us/step - loss: 0.5573 - val_loss: 0.5236\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 539us/step - loss: 0.5418 - val_loss: 0.5275\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 546us/step - loss: 0.5276 - val_loss: 0.5573\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 532us/step - loss: 0.5146 - val_loss: 0.6370\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 540us/step - loss: 0.5030 - val_loss: 0.7130\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 528us/step - loss: 0.4923 - val_loss: 0.7504\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 536us/step - loss: 0.4825 - val_loss: 0.8339\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 523us/step - loss: 0.4735 - val_loss: 0.8768\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 540us/step - loss: 0.4652 - val_loss: 0.9219\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 538us/step - loss: 0.4578 - val_loss: 0.9643\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 534us/step - loss: 0.4508 - val_loss: 1.0214\n",
      "121/121 [==============================] - 0s 315us/step - loss: 0.4733\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 825us/step - loss: 2.6515 - val_loss: 1.5839\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 541us/step - loss: 0.9146 - val_loss: 1.0636\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 548us/step - loss: 0.7383 - val_loss: 0.7693\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 548us/step - loss: 0.6890 - val_loss: 0.6594\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 540us/step - loss: 0.6595 - val_loss: 0.6231\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.6358 - val_loss: 0.5958\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.6142 - val_loss: 0.5758\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 540us/step - loss: 0.5950 - val_loss: 0.5555\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 539us/step - loss: 0.5774 - val_loss: 0.5386\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 571us/step - loss: 0.5610 - val_loss: 0.5241\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.5457 - val_loss: 0.5090\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 547us/step - loss: 0.5317 - val_loss: 0.4962\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 532us/step - loss: 0.5189 - val_loss: 0.4860\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 548us/step - loss: 0.5071 - val_loss: 0.4784\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 532us/step - loss: 0.4962 - val_loss: 0.4678\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 536us/step - loss: 0.4865 - val_loss: 0.4552\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 0.4774 - val_loss: 0.4467\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 0.4691 - val_loss: 0.4382\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.4618 - val_loss: 0.4317\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 541us/step - loss: 0.4549 - val_loss: 0.4278\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 523us/step - loss: 0.4486 - val_loss: 0.4239\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 536us/step - loss: 0.4430 - val_loss: 0.4181\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 545us/step - loss: 0.4378 - val_loss: 0.4147\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 542us/step - loss: 0.4330 - val_loss: 0.4186\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 536us/step - loss: 0.4288 - val_loss: 0.4081\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.4248 - val_loss: 0.4039\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.4211 - val_loss: 0.4028\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 540us/step - loss: 0.4177 - val_loss: 0.3993\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 0.4144 - val_loss: 0.4087\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.4119 - val_loss: 0.3992\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 548us/step - loss: 0.4091 - val_loss: 0.3932\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 548us/step - loss: 0.4066 - val_loss: 0.4000\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 536us/step - loss: 0.4042 - val_loss: 0.3941\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.4020 - val_loss: 0.4077\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 538us/step - loss: 0.4003 - val_loss: 0.3902\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 539us/step - loss: 0.3981 - val_loss: 0.3883\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 0.3965 - val_loss: 0.3823\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 540us/step - loss: 0.3947 - val_loss: 0.3913\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 536us/step - loss: 0.3930 - val_loss: 0.3847\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 0.3914 - val_loss: 0.3848\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 610us/step - loss: 0.3898 - val_loss: 0.4007\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 530us/step - loss: 0.3887 - val_loss: 0.3958\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 540us/step - loss: 0.3872 - val_loss: 0.3768\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 0.3860 - val_loss: 0.3859\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.3848 - val_loss: 0.3857\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 551us/step - loss: 0.3836 - val_loss: 0.3821\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 568us/step - loss: 0.3824 - val_loss: 0.3720\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 0.3815 - val_loss: 0.3729\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 585us/step - loss: 0.3801 - val_loss: 0.3871\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 0.3792 - val_loss: 0.3909\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 536us/step - loss: 0.3781 - val_loss: 0.3867\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.3772 - val_loss: 0.3893\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 0.3763 - val_loss: 0.3758\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 532us/step - loss: 0.3753 - val_loss: 0.3670\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.3743 - val_loss: 0.3687\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 542us/step - loss: 0.3733 - val_loss: 0.3742\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.3724 - val_loss: 0.3802\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 575us/step - loss: 0.3718 - val_loss: 0.3805\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 0.3709 - val_loss: 0.3785\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 548us/step - loss: 0.3699 - val_loss: 0.3665\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.3692 - val_loss: 0.3683\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 0.3683 - val_loss: 0.3812\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.3678 - val_loss: 0.3656\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 577us/step - loss: 0.3670 - val_loss: 0.3632\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 534us/step - loss: 0.3663 - val_loss: 0.3587\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 557us/step - loss: 0.3654 - val_loss: 0.3726\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 554us/step - loss: 0.3649 - val_loss: 0.3596\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 565us/step - loss: 0.3641 - val_loss: 0.3710\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.3634 - val_loss: 0.3593\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 558us/step - loss: 0.3627 - val_loss: 0.3676\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 0.3621 - val_loss: 0.3571\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 0.3615 - val_loss: 0.3666\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 540us/step - loss: 0.3608 - val_loss: 0.3552\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 540us/step - loss: 0.3604 - val_loss: 0.3550\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 565us/step - loss: 0.3598 - val_loss: 0.3640\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 0.3591 - val_loss: 0.3714\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 565us/step - loss: 0.3587 - val_loss: 0.3622\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 581us/step - loss: 0.3582 - val_loss: 0.3585\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 575us/step - loss: 0.3577 - val_loss: 0.3533\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 585us/step - loss: 0.3571 - val_loss: 0.3629\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 565us/step - loss: 0.3568 - val_loss: 0.3573\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 565us/step - loss: 0.3563 - val_loss: 0.3639\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 585us/step - loss: 0.3558 - val_loss: 0.3599\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 565us/step - loss: 0.3553 - val_loss: 0.3708\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 593us/step - loss: 0.3548 - val_loss: 0.3483\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 593us/step - loss: 0.3545 - val_loss: 0.3559\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 581us/step - loss: 0.3539 - val_loss: 0.3708\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 596us/step - loss: 0.3536 - val_loss: 0.3613\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 0.3532 - val_loss: 0.3682\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 589us/step - loss: 0.3527 - val_loss: 0.3521\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 592us/step - loss: 0.3522 - val_loss: 0.3589\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 554us/step - loss: 0.3520 - val_loss: 0.3486\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.3514 - val_loss: 0.3651\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.3511 - val_loss: 0.3607\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.3506 - val_loss: 0.3602\n",
      "121/121 [==============================] - 0s 297us/step - loss: 0.3523\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 863us/step - loss: 4.0643 - val_loss: 3.2009\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 2.2480 - val_loss: 2.4298\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 547us/step - loss: 1.5086 - val_loss: 1.4896\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 534us/step - loss: 1.1665 - val_loss: 1.0711\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 537us/step - loss: 0.9972 - val_loss: 0.9682\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 536us/step - loss: 0.8997 - val_loss: 0.9217\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.8356 - val_loss: 0.9071\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 0.7918 - val_loss: 0.8702\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 569us/step - loss: 0.7605 - val_loss: 0.7975\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 668us/step - loss: 0.7361 - val_loss: 0.8103\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 536us/step - loss: 0.7181 - val_loss: 0.7776\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 528us/step - loss: 0.7036 - val_loss: 0.7244\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 535us/step - loss: 0.6905 - val_loss: 0.7672\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.6805 - val_loss: 0.7438\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 0.6712 - val_loss: 0.7198\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 519us/step - loss: 0.6621 - val_loss: 0.7207\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 565us/step - loss: 0.6544 - val_loss: 0.7010\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 532us/step - loss: 0.6465 - val_loss: 0.7145\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 536us/step - loss: 0.6395 - val_loss: 0.6949\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 0.6327 - val_loss: 0.7121\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 523us/step - loss: 0.6270 - val_loss: 0.6426\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 577us/step - loss: 0.6196 - val_loss: 0.6696\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 539us/step - loss: 0.6140 - val_loss: 0.6543\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.6080 - val_loss: 0.6446\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 577us/step - loss: 0.6024 - val_loss: 0.6223\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 528us/step - loss: 0.5967 - val_loss: 0.5918\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 523us/step - loss: 0.5907 - val_loss: 0.6178\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 507us/step - loss: 0.5858 - val_loss: 0.5816\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 515us/step - loss: 0.5801 - val_loss: 0.5879\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 511us/step - loss: 0.5749 - val_loss: 0.5854\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.5697 - val_loss: 0.5831\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 589us/step - loss: 0.5647 - val_loss: 0.5557\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 536us/step - loss: 0.5594 - val_loss: 0.5650\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 528us/step - loss: 0.5546 - val_loss: 0.5559\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 621us/step - loss: 0.5495 - val_loss: 0.5335\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 841us/step - loss: 0.5444 - val_loss: 0.5536\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 651us/step - loss: 0.5400 - val_loss: 0.5087\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 573us/step - loss: 0.5348 - val_loss: 0.5381\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 618us/step - loss: 0.5305 - val_loss: 0.5160\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 565us/step - loss: 0.5259 - val_loss: 0.5112\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 606us/step - loss: 0.5214 - val_loss: 0.5088\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 532us/step - loss: 0.5172 - val_loss: 0.4918\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 519us/step - loss: 0.5129 - val_loss: 0.4886\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 0.5085 - val_loss: 0.4893\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 528us/step - loss: 0.5044 - val_loss: 0.4880\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 518us/step - loss: 0.5004 - val_loss: 0.4767\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 532us/step - loss: 0.4964 - val_loss: 0.4768\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 569us/step - loss: 0.4924 - val_loss: 0.4764\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 528us/step - loss: 0.4884 - val_loss: 0.4687\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 515us/step - loss: 0.4842 - val_loss: 0.4701\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.4806 - val_loss: 0.4586\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 0.4767 - val_loss: 0.4542\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.4729 - val_loss: 0.4488\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 0.4694 - val_loss: 0.4399\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 539us/step - loss: 0.4655 - val_loss: 0.4421\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.4623 - val_loss: 0.4330\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 584us/step - loss: 0.4587 - val_loss: 0.4314\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 532us/step - loss: 0.4553 - val_loss: 0.4284\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 530us/step - loss: 0.4522 - val_loss: 0.4239\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 573us/step - loss: 0.4489 - val_loss: 0.4210\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 536us/step - loss: 0.4459 - val_loss: 0.4187\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 540us/step - loss: 0.4428 - val_loss: 0.4160\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 0.4397 - val_loss: 0.4152\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 523us/step - loss: 0.4372 - val_loss: 0.4107\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 519us/step - loss: 0.4343 - val_loss: 0.4092\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 569us/step - loss: 0.4318 - val_loss: 0.4061\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 548us/step - loss: 0.4291 - val_loss: 0.4037\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 531us/step - loss: 0.4267 - val_loss: 0.4066\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 514us/step - loss: 0.4243 - val_loss: 0.4007\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 575us/step - loss: 0.4218 - val_loss: 0.3977\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 569us/step - loss: 0.4197 - val_loss: 0.3961\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 0.4174 - val_loss: 0.3970\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 548us/step - loss: 0.4151 - val_loss: 0.3940\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 536us/step - loss: 0.4132 - val_loss: 0.3948\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 655us/step - loss: 0.4110 - val_loss: 0.3969\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 565us/step - loss: 0.4090 - val_loss: 0.3944\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 534us/step - loss: 0.4072 - val_loss: 0.3930\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 548us/step - loss: 0.4052 - val_loss: 0.3959\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 548us/step - loss: 0.4035 - val_loss: 0.3876\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 553us/step - loss: 0.4017 - val_loss: 0.3879\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 548us/step - loss: 0.4002 - val_loss: 0.3914\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.3984 - val_loss: 0.4011\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 565us/step - loss: 0.3970 - val_loss: 0.3949\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 593us/step - loss: 0.3955 - val_loss: 0.3952\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 585us/step - loss: 0.3939 - val_loss: 0.3853\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 582us/step - loss: 0.3922 - val_loss: 0.4022\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 577us/step - loss: 0.3913 - val_loss: 0.3890\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 563us/step - loss: 0.3900 - val_loss: 0.3886\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.3887 - val_loss: 0.3854\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 567us/step - loss: 0.3875 - val_loss: 0.3914\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 565us/step - loss: 0.3864 - val_loss: 0.3857\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 631us/step - loss: 0.3852 - val_loss: 0.3878\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 0.3840 - val_loss: 0.3838\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.3829 - val_loss: 0.3826\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.3818 - val_loss: 0.3848\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 0.3806 - val_loss: 0.3876\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.3797 - val_loss: 0.3765\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 0.3787 - val_loss: 0.3781\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 548us/step - loss: 0.3775 - val_loss: 0.4042\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 577us/step - loss: 0.3769 - val_loss: 0.3800\n",
      "121/121 [==============================] - 0s 321us/step - loss: 0.3919\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 873us/step - loss: 2.9952 - val_loss: 2.4994\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 1.3166 - val_loss: 2.5260\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 540us/step - loss: 1.0186 - val_loss: 2.1424\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 0.8597 - val_loss: 1.7394\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 548us/step - loss: 0.7588 - val_loss: 1.4493\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.6975 - val_loss: 1.2538\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 551us/step - loss: 0.6591 - val_loss: 1.1114\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 542us/step - loss: 0.6324 - val_loss: 0.9954\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 548us/step - loss: 0.6122 - val_loss: 0.9118\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.5953 - val_loss: 0.8420\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 540us/step - loss: 0.5805 - val_loss: 0.7890\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 569us/step - loss: 0.5673 - val_loss: 0.7336\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.5555 - val_loss: 0.6950\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 631us/step - loss: 0.5447 - val_loss: 0.6626\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 589us/step - loss: 0.5346 - val_loss: 0.6261\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 548us/step - loss: 0.5252 - val_loss: 0.6025\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 528us/step - loss: 0.5165 - val_loss: 0.5756\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 532us/step - loss: 0.5083 - val_loss: 0.5552\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 581us/step - loss: 0.5006 - val_loss: 0.5367\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 534us/step - loss: 0.4935 - val_loss: 0.5207\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 536us/step - loss: 0.4868 - val_loss: 0.5045\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 540us/step - loss: 0.4806 - val_loss: 0.4940\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 548us/step - loss: 0.4748 - val_loss: 0.4845\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 565us/step - loss: 0.4695 - val_loss: 0.4729\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 548us/step - loss: 0.4644 - val_loss: 0.4640\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 532us/step - loss: 0.4597 - val_loss: 0.4563\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.4551 - val_loss: 0.4518\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.4510 - val_loss: 0.4441\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.4467 - val_loss: 0.4440\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 540us/step - loss: 0.4436 - val_loss: 0.4349\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.4399 - val_loss: 0.4290\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 540us/step - loss: 0.4366 - val_loss: 0.4258\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 548us/step - loss: 0.4337 - val_loss: 0.4224\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 540us/step - loss: 0.4307 - val_loss: 0.4214\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 532us/step - loss: 0.4280 - val_loss: 0.4192\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 0.4256 - val_loss: 0.4136\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.4232 - val_loss: 0.4135\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 519us/step - loss: 0.4210 - val_loss: 0.4103\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 517us/step - loss: 0.4188 - val_loss: 0.4089\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 532us/step - loss: 0.4168 - val_loss: 0.4081\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 536us/step - loss: 0.4149 - val_loss: 0.4067\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 543us/step - loss: 0.4132 - val_loss: 0.4060\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 566us/step - loss: 0.4114 - val_loss: 0.4029\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 622us/step - loss: 0.4099 - val_loss: 0.4028\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 512us/step - loss: 0.4082 - val_loss: 0.4023\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 619us/step - loss: 0.4068 - val_loss: 0.3996\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 574us/step - loss: 0.4054 - val_loss: 0.3995\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 585us/step - loss: 0.4041 - val_loss: 0.3987\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 569us/step - loss: 0.4028 - val_loss: 0.3999\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 598us/step - loss: 0.4016 - val_loss: 0.3987\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 610us/step - loss: 0.4001 - val_loss: 0.3949\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 548us/step - loss: 0.3994 - val_loss: 0.3978\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 569us/step - loss: 0.3982 - val_loss: 0.3971\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 573us/step - loss: 0.3971 - val_loss: 0.3971\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 0.3961 - val_loss: 0.3983\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 598us/step - loss: 0.3951 - val_loss: 0.3989\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 588us/step - loss: 0.3941 - val_loss: 0.3971\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 573us/step - loss: 0.3933 - val_loss: 0.3992\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 577us/step - loss: 0.3924 - val_loss: 0.3998\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 598us/step - loss: 0.3913 - val_loss: 0.3977\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 631us/step - loss: 0.3906 - val_loss: 0.4013\n",
      "121/121 [==============================] - 0s 338us/step - loss: 0.3961\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 849us/step - loss: 5.2087 - val_loss: 3.5601\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 528us/step - loss: 2.9435 - val_loss: 2.9645\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 558us/step - loss: 1.8223 - val_loss: 3.4480\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 565us/step - loss: 1.3092 - val_loss: 3.6296\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 528us/step - loss: 1.1023 - val_loss: 2.2463\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 569us/step - loss: 0.9724 - val_loss: 1.5117\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 593us/step - loss: 0.8777 - val_loss: 1.1044\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 0.8087 - val_loss: 0.8385\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 573us/step - loss: 0.7576 - val_loss: 0.7350\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 602us/step - loss: 0.7196 - val_loss: 0.6870\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 558us/step - loss: 0.6902 - val_loss: 0.6664\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 571us/step - loss: 0.6670 - val_loss: 0.6532\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 596us/step - loss: 0.6480 - val_loss: 0.6382\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.6315 - val_loss: 0.6260\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 546us/step - loss: 0.6171 - val_loss: 0.6163\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 546us/step - loss: 0.6042 - val_loss: 0.6157\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 532us/step - loss: 0.5928 - val_loss: 0.6064\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.5821 - val_loss: 0.5930\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 523us/step - loss: 0.5722 - val_loss: 0.5902\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 540us/step - loss: 0.5634 - val_loss: 0.5690\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 519us/step - loss: 0.5547 - val_loss: 0.5544\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 532us/step - loss: 0.5466 - val_loss: 0.5531\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.5391 - val_loss: 0.5375\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 559us/step - loss: 0.5318 - val_loss: 0.5221\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 565us/step - loss: 0.5250 - val_loss: 0.5195\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 570us/step - loss: 0.5185 - val_loss: 0.5085\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 593us/step - loss: 0.5122 - val_loss: 0.5119\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 598us/step - loss: 0.5065 - val_loss: 0.4996\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 598us/step - loss: 0.5007 - val_loss: 0.4905\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 589us/step - loss: 0.4955 - val_loss: 0.4912\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 519us/step - loss: 0.4903 - val_loss: 0.4836\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 585us/step - loss: 0.4854 - val_loss: 0.4708\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.4807 - val_loss: 0.4673\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 581us/step - loss: 0.4761 - val_loss: 0.4582\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 602us/step - loss: 0.4720 - val_loss: 0.4579\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 0.4680 - val_loss: 0.4467\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 569us/step - loss: 0.4642 - val_loss: 0.4400\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 0.4606 - val_loss: 0.4395\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 600us/step - loss: 0.4571 - val_loss: 0.4334\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 565us/step - loss: 0.4538 - val_loss: 0.4307\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 588us/step - loss: 0.4505 - val_loss: 0.4226\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 622us/step - loss: 0.4478 - val_loss: 0.4193\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 534us/step - loss: 0.4449 - val_loss: 0.4184\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 534us/step - loss: 0.4424 - val_loss: 0.4132\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.4399 - val_loss: 0.4118\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 585us/step - loss: 0.4375 - val_loss: 0.4096\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 577us/step - loss: 0.4353 - val_loss: 0.4061\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 569us/step - loss: 0.4333 - val_loss: 0.4040\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 511us/step - loss: 0.4311 - val_loss: 0.4018\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 532us/step - loss: 0.4294 - val_loss: 0.3995\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.4274 - val_loss: 0.3979\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 543us/step - loss: 0.4258 - val_loss: 0.3962\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 540us/step - loss: 0.4240 - val_loss: 0.3945\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 586us/step - loss: 0.4226 - val_loss: 0.3931\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 0.4210 - val_loss: 0.3927\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 585us/step - loss: 0.4195 - val_loss: 0.3921\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 532us/step - loss: 0.4181 - val_loss: 0.3909\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 536us/step - loss: 0.4168 - val_loss: 0.3906\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.4155 - val_loss: 0.3896\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 569us/step - loss: 0.4141 - val_loss: 0.3877\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 587us/step - loss: 0.4129 - val_loss: 0.3926\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 532us/step - loss: 0.4118 - val_loss: 0.3920\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 522us/step - loss: 0.4106 - val_loss: 0.3905\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 565us/step - loss: 0.4094 - val_loss: 0.3912\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 591us/step - loss: 0.4084 - val_loss: 0.3934\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 568us/step - loss: 0.4071 - val_loss: 0.4007\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 577us/step - loss: 0.4062 - val_loss: 0.3945\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 536us/step - loss: 0.4051 - val_loss: 0.3994\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 503us/step - loss: 0.4041 - val_loss: 0.4028\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 536us/step - loss: 0.4031 - val_loss: 0.4056\n",
      "121/121 [==============================] - 0s 338us/step - loss: 0.4048\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 711us/step - loss: 1.7412 - val_loss: 2.8767\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.8514 - val_loss: 18.6358\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 490us/step - loss: 0.7199 - val_loss: 24.0961\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 509us/step - loss: 0.9571 - val_loss: 91.2596\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 518us/step - loss: 1.0532 - val_loss: 147.3911\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 3.2162 - val_loss: 309.0291\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 515us/step - loss: 3.1905 - val_loss: 710.6489\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 511us/step - loss: 12.0783 - val_loss: 1609.7476\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 16.9645 - val_loss: 3451.5923\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 519us/step - loss: 58.7665 - val_loss: 8190.5034\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 515us/step - loss: 94.5754 - val_loss: 18879.0078\n",
      "121/121 [==============================] - 0s 280us/step - loss: 48.3720\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 709us/step - loss: 1.5290 - val_loss: 4.8147\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 468us/step - loss: 0.6583 - val_loss: 11.3409\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 515us/step - loss: 0.5972 - val_loss: 16.7306\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 503us/step - loss: 0.5629 - val_loss: 19.3395\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 487us/step - loss: 0.5420 - val_loss: 20.6858\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 501us/step - loss: 0.5283 - val_loss: 21.3486\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 514us/step - loss: 0.5193 - val_loss: 21.2784\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 509us/step - loss: 0.5131 - val_loss: 21.6215\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.5086 - val_loss: 21.1987\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 490us/step - loss: 0.5064 - val_loss: 19.3722\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.5050 - val_loss: 20.1974\n",
      "121/121 [==============================] - 0s 305us/step - loss: 0.9819\n",
      "Epoch 1/100\n",
      "  1/242 [..............................] - ETA: 0s - loss: 7.1490WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5479 - val_loss: 0.6493\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.6631 - val_loss: 2.3043\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.6169 - val_loss: 1.2292\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 518us/step - loss: 0.5758 - val_loss: 4.5465\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 488us/step - loss: 0.6227 - val_loss: 37.9706\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 515us/step - loss: 0.7587 - val_loss: 37.1782\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 490us/step - loss: 0.9294 - val_loss: 66.8003\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 503us/step - loss: 1.3776 - val_loss: 122.4832\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 499us/step - loss: 1.9791 - val_loss: 190.0985\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 507us/step - loss: 1.2311 - val_loss: 172.5283\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 4.0663 - val_loss: 213.2607\n",
      "121/121 [==============================] - 0s 330us/step - loss: 1.0024\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 762us/step - loss: 1.1190 - val_loss: 38.5168\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 507us/step - loss: 1.0464 - val_loss: 32.7105\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 522us/step - loss: 0.7862 - val_loss: 106.9947\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.5380 - val_loss: 0.4181\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 546us/step - loss: 0.4011 - val_loss: 0.3788\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 534us/step - loss: 0.3816 - val_loss: 0.3757\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 519us/step - loss: 0.3711 - val_loss: 0.3664\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 548us/step - loss: 0.3641 - val_loss: 0.3651\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 548us/step - loss: 0.3604 - val_loss: 0.3713\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.3576 - val_loss: 0.3604\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 540us/step - loss: 0.3552 - val_loss: 0.3635\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 540us/step - loss: 0.3517 - val_loss: 0.3630\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 516us/step - loss: 0.3492 - val_loss: 0.3576\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 511us/step - loss: 0.3477 - val_loss: 0.3566\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.3459 - val_loss: 0.3569\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 550us/step - loss: 0.3450 - val_loss: 0.3568\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 517us/step - loss: 0.3433 - val_loss: 0.3544\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 538us/step - loss: 0.3428 - val_loss: 0.3619\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 540us/step - loss: 0.3406 - val_loss: 0.3706\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 511us/step - loss: 0.3395 - val_loss: 0.3675\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 503us/step - loss: 0.3384 - val_loss: 0.3732\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.3383 - val_loss: 0.3714\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 548us/step - loss: 0.3365 - val_loss: 0.3639\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.3367 - val_loss: 0.3678\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 515us/step - loss: 0.3360 - val_loss: 0.3705\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.3342 - val_loss: 0.3622\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.3345 - val_loss: 0.3591\n",
      "121/121 [==============================] - 0s 313us/step - loss: 0.3551\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 758us/step - loss: 0.9108 - val_loss: 0.6338\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 490us/step - loss: 0.5515 - val_loss: 1.2441\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.4752 - val_loss: 1.3079\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 528us/step - loss: 0.4444 - val_loss: 0.9366\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 511us/step - loss: 0.4261 - val_loss: 0.5304\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 528us/step - loss: 0.4134 - val_loss: 0.3861\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 519us/step - loss: 0.4079 - val_loss: 0.4624\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 527us/step - loss: 0.3991 - val_loss: 0.5256\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 519us/step - loss: 0.3936 - val_loss: 0.6619\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.3917 - val_loss: 0.5785\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 545us/step - loss: 0.3855 - val_loss: 0.7134\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.3806 - val_loss: 0.7684\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 532us/step - loss: 0.3798 - val_loss: 0.8465\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 515us/step - loss: 0.3798 - val_loss: 0.8148\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 548us/step - loss: 0.3749 - val_loss: 0.8079\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 536us/step - loss: 0.3741 - val_loss: 0.8055\n",
      "121/121 [==============================] - 0s 321us/step - loss: 0.3842\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 758us/step - loss: 0.7659 - val_loss: 11.2530\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.5864 - val_loss: 16.0858\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 536us/step - loss: 0.5723 - val_loss: 3.3018\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.4865 - val_loss: 0.4081\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 542us/step - loss: 0.4302 - val_loss: 0.4151\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 499us/step - loss: 0.4177 - val_loss: 0.4407\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 511us/step - loss: 0.4126 - val_loss: 0.4371\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 519us/step - loss: 0.4051 - val_loss: 0.4306\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 511us/step - loss: 0.3988 - val_loss: 0.4444\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 519us/step - loss: 0.3965 - val_loss: 0.4109\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 585us/step - loss: 0.3932 - val_loss: 0.4555\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 511us/step - loss: 0.3893 - val_loss: 0.4265\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 566us/step - loss: 0.3848 - val_loss: 0.4020\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.3814 - val_loss: 0.4312\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 536us/step - loss: 0.3792 - val_loss: 0.4023\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 503us/step - loss: 0.3757 - val_loss: 0.4201\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 536us/step - loss: 0.3735 - val_loss: 0.3847\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 495us/step - loss: 0.3758 - val_loss: 0.3970\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 503us/step - loss: 0.3705 - val_loss: 0.4144\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 532us/step - loss: 0.3679 - val_loss: 0.3926\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.3710 - val_loss: 0.4085\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 532us/step - loss: 0.3694 - val_loss: 0.3650\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 511us/step - loss: 0.3658 - val_loss: 0.3780\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 528us/step - loss: 0.3628 - val_loss: 0.4056\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 536us/step - loss: 0.3620 - val_loss: 0.3508\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 519us/step - loss: 0.3625 - val_loss: 0.3651\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 543us/step - loss: 0.3592 - val_loss: 0.3996\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 522us/step - loss: 0.3593 - val_loss: 0.3534\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 532us/step - loss: 0.3656 - val_loss: 0.3899\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 505us/step - loss: 0.3642 - val_loss: 0.4015\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 493us/step - loss: 0.3561 - val_loss: 0.3635\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 525us/step - loss: 0.3543 - val_loss: 0.4009\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.3537 - val_loss: 0.3953\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 499us/step - loss: 0.3531 - val_loss: 0.3787\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 536us/step - loss: 0.3542 - val_loss: 0.3535\n",
      "121/121 [==============================] - 0s 321us/step - loss: 0.3514\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 805us/step - loss: 2.3696 - val_loss: 4.8102\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 547us/step - loss: 1.3301 - val_loss: 3.5633\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 577us/step - loss: 1.1104 - val_loss: 2.3719\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 551us/step - loss: 0.9922 - val_loss: 1.6216\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 571us/step - loss: 0.9096 - val_loss: 1.2676\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 0.8488 - val_loss: 1.0831\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 536us/step - loss: 0.8019 - val_loss: 0.9445\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 581us/step - loss: 0.7645 - val_loss: 0.8404\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 581us/step - loss: 0.7342 - val_loss: 0.7676\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 589us/step - loss: 0.7091 - val_loss: 0.7137\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 0.6881 - val_loss: 0.6728\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 548us/step - loss: 0.6700 - val_loss: 0.6423\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 589us/step - loss: 0.6543 - val_loss: 0.6201\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 598us/step - loss: 0.6403 - val_loss: 0.6039\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 551us/step - loss: 0.6280 - val_loss: 0.5893\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 580us/step - loss: 0.6165 - val_loss: 0.5776\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 532us/step - loss: 0.6064 - val_loss: 0.5678\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 0.5968 - val_loss: 0.5593\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 0.5877 - val_loss: 0.5520\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 589us/step - loss: 0.5795 - val_loss: 0.5448\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 598us/step - loss: 0.5715 - val_loss: 0.5382\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 585us/step - loss: 0.5640 - val_loss: 0.5319\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 573us/step - loss: 0.5567 - val_loss: 0.5260\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 548us/step - loss: 0.5497 - val_loss: 0.5208\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 585us/step - loss: 0.5434 - val_loss: 0.5149\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 574us/step - loss: 0.5371 - val_loss: 0.5092\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 573us/step - loss: 0.5311 - val_loss: 0.5038\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 569us/step - loss: 0.5253 - val_loss: 0.4982\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 577us/step - loss: 0.5197 - val_loss: 0.4929\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 602us/step - loss: 0.5144 - val_loss: 0.4879\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 589us/step - loss: 0.5093 - val_loss: 0.4829\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 573us/step - loss: 0.5044 - val_loss: 0.4779\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 593us/step - loss: 0.4997 - val_loss: 0.4730\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 584us/step - loss: 0.4953 - val_loss: 0.4682\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 515us/step - loss: 0.4909 - val_loss: 0.4635\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.4867 - val_loss: 0.4592\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 581us/step - loss: 0.4828 - val_loss: 0.4546\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 567us/step - loss: 0.4791 - val_loss: 0.4506\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 577us/step - loss: 0.4754 - val_loss: 0.4466\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.4720 - val_loss: 0.4431\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 0.4687 - val_loss: 0.4397\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 577us/step - loss: 0.4656 - val_loss: 0.4365\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 536us/step - loss: 0.4627 - val_loss: 0.4334\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 0.4597 - val_loss: 0.4310\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 543us/step - loss: 0.4572 - val_loss: 0.4285\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 585us/step - loss: 0.4545 - val_loss: 0.4264\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 581us/step - loss: 0.4524 - val_loss: 0.4246\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 0.4500 - val_loss: 0.4230\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 536us/step - loss: 0.4478 - val_loss: 0.4218\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 585us/step - loss: 0.4457 - val_loss: 0.4206\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 581us/step - loss: 0.4436 - val_loss: 0.4194\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 0.4418 - val_loss: 0.4189\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 585us/step - loss: 0.4400 - val_loss: 0.4182\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 573us/step - loss: 0.4381 - val_loss: 0.4174\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 534us/step - loss: 0.4363 - val_loss: 0.4171\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 0.4347 - val_loss: 0.4168\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 593us/step - loss: 0.4331 - val_loss: 0.4166\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 587us/step - loss: 0.4316 - val_loss: 0.4167\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 558us/step - loss: 0.4301 - val_loss: 0.4163\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 0.4285 - val_loss: 0.4161\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 565us/step - loss: 0.4274 - val_loss: 0.4163\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.4260 - val_loss: 0.4165\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 0.4246 - val_loss: 0.4162\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 577us/step - loss: 0.4235 - val_loss: 0.4168\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 581us/step - loss: 0.4222 - val_loss: 0.4170\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 0.4210 - val_loss: 0.4172\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 548us/step - loss: 0.4198 - val_loss: 0.4168\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 542us/step - loss: 0.4187 - val_loss: 0.4173\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 584us/step - loss: 0.4177 - val_loss: 0.4172\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 585us/step - loss: 0.4164 - val_loss: 0.4170\n",
      "121/121 [==============================] - 0s 297us/step - loss: 0.4312\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 822us/step - loss: 5.0320 - val_loss: 3.3266\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 511us/step - loss: 2.2012 - val_loss: 3.0131\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 536us/step - loss: 1.3159 - val_loss: 3.0212\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 1.0203 - val_loss: 2.7112\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 563us/step - loss: 0.8752 - val_loss: 2.2781\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.7790 - val_loss: 1.9026\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 602us/step - loss: 0.7074 - val_loss: 1.6153\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 616us/step - loss: 0.6546 - val_loss: 1.3578\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 565us/step - loss: 0.6163 - val_loss: 1.1957\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 532us/step - loss: 0.5886 - val_loss: 1.1023\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 548us/step - loss: 0.5684 - val_loss: 1.0351\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 0.5532 - val_loss: 0.9778\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 593us/step - loss: 0.5414 - val_loss: 0.9390\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 585us/step - loss: 0.5317 - val_loss: 0.9152\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.5234 - val_loss: 0.8884\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 584us/step - loss: 0.5162 - val_loss: 0.8738\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 571us/step - loss: 0.5096 - val_loss: 0.8580\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 576us/step - loss: 0.5036 - val_loss: 0.8450\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 579us/step - loss: 0.4981 - val_loss: 0.8306\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 585us/step - loss: 0.4929 - val_loss: 0.8244\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 577us/step - loss: 0.4881 - val_loss: 0.8128\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 589us/step - loss: 0.4835 - val_loss: 0.8092\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 585us/step - loss: 0.4791 - val_loss: 0.8048\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.4750 - val_loss: 0.7967\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 581us/step - loss: 0.4711 - val_loss: 0.7907\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 587us/step - loss: 0.4675 - val_loss: 0.7858\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 568us/step - loss: 0.4640 - val_loss: 0.7842\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 581us/step - loss: 0.4606 - val_loss: 0.7792\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 0.4573 - val_loss: 0.7862\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 589us/step - loss: 0.4545 - val_loss: 0.7790\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 581us/step - loss: 0.4516 - val_loss: 0.7752\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 589us/step - loss: 0.4488 - val_loss: 0.7758\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 581us/step - loss: 0.4463 - val_loss: 0.7762\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 585us/step - loss: 0.4437 - val_loss: 0.7797\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 581us/step - loss: 0.4414 - val_loss: 0.7809\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 540us/step - loss: 0.4391 - val_loss: 0.7750\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 548us/step - loss: 0.4369 - val_loss: 0.7821\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 577us/step - loss: 0.4348 - val_loss: 0.7821\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 526us/step - loss: 0.4328 - val_loss: 0.7833\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 585us/step - loss: 0.4309 - val_loss: 0.7874\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 573us/step - loss: 0.4290 - val_loss: 0.7894\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 581us/step - loss: 0.4273 - val_loss: 0.7916\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 577us/step - loss: 0.4255 - val_loss: 0.7884\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 573us/step - loss: 0.4239 - val_loss: 0.7947\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 581us/step - loss: 0.4222 - val_loss: 0.7988\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 519us/step - loss: 0.4206 - val_loss: 0.7959\n",
      "121/121 [==============================] - 0s 305us/step - loss: 0.4325\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 814us/step - loss: 4.9757 - val_loss: 3.8494\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 537us/step - loss: 2.4849 - val_loss: 5.0815\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 540us/step - loss: 1.5034 - val_loss: 4.1164\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 1.1287 - val_loss: 3.4111\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.9938 - val_loss: 1.9845\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 519us/step - loss: 0.9144 - val_loss: 1.4370\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.8567 - val_loss: 1.1138\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 0.8115 - val_loss: 0.8893\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 585us/step - loss: 0.7733 - val_loss: 0.7835\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 548us/step - loss: 0.7411 - val_loss: 0.7153\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 536us/step - loss: 0.7139 - val_loss: 0.6737\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 553us/step - loss: 0.6909 - val_loss: 0.6495\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 554us/step - loss: 0.6718 - val_loss: 0.6317\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.6556 - val_loss: 0.6175\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 540us/step - loss: 0.6417 - val_loss: 0.6055\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 589us/step - loss: 0.6295 - val_loss: 0.5992\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 0.6190 - val_loss: 0.5882\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 606us/step - loss: 0.6094 - val_loss: 0.5799\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 593us/step - loss: 0.6007 - val_loss: 0.5781\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 568us/step - loss: 0.5930 - val_loss: 0.5698\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 550us/step - loss: 0.5856 - val_loss: 0.5626\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 589us/step - loss: 0.5787 - val_loss: 0.5581\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 581us/step - loss: 0.5723 - val_loss: 0.5468\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 0.5659 - val_loss: 0.5389\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 585us/step - loss: 0.5601 - val_loss: 0.5343\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 577us/step - loss: 0.5545 - val_loss: 0.5277\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 536us/step - loss: 0.5489 - val_loss: 0.5270\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 593us/step - loss: 0.5439 - val_loss: 0.5191\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 581us/step - loss: 0.5384 - val_loss: 0.5148\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 577us/step - loss: 0.5336 - val_loss: 0.5107\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 554us/step - loss: 0.5286 - val_loss: 0.5083\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 584us/step - loss: 0.5240 - val_loss: 0.5023\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 563us/step - loss: 0.5194 - val_loss: 0.4989\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 576us/step - loss: 0.5152 - val_loss: 0.4931\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 606us/step - loss: 0.5110 - val_loss: 0.4891\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 593us/step - loss: 0.5068 - val_loss: 0.4850\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 581us/step - loss: 0.5028 - val_loss: 0.4814\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 577us/step - loss: 0.4988 - val_loss: 0.4777\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 0.4950 - val_loss: 0.4745\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 0.4914 - val_loss: 0.4713\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 598us/step - loss: 0.4877 - val_loss: 0.4688\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 602us/step - loss: 0.4845 - val_loss: 0.4655\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 589us/step - loss: 0.4812 - val_loss: 0.4623\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 580us/step - loss: 0.4781 - val_loss: 0.4599\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 550us/step - loss: 0.4749 - val_loss: 0.4570\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 548us/step - loss: 0.4720 - val_loss: 0.4540\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 536us/step - loss: 0.4693 - val_loss: 0.4529\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 577us/step - loss: 0.4665 - val_loss: 0.4511\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 573us/step - loss: 0.4639 - val_loss: 0.4491\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 585us/step - loss: 0.4614 - val_loss: 0.4465\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 589us/step - loss: 0.4588 - val_loss: 0.4441\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 581us/step - loss: 0.4566 - val_loss: 0.4422\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 593us/step - loss: 0.4543 - val_loss: 0.4415\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 577us/step - loss: 0.4522 - val_loss: 0.4408\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 0.4501 - val_loss: 0.4410\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 546us/step - loss: 0.4481 - val_loss: 0.4415\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 565us/step - loss: 0.4463 - val_loss: 0.4381\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 589us/step - loss: 0.4444 - val_loss: 0.4365\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 0.4426 - val_loss: 0.4354\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 589us/step - loss: 0.4409 - val_loss: 0.4317\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 581us/step - loss: 0.4393 - val_loss: 0.4342\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 585us/step - loss: 0.4377 - val_loss: 0.4358\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 550us/step - loss: 0.4362 - val_loss: 0.4331\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 600us/step - loss: 0.4347 - val_loss: 0.4301\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 0.4333 - val_loss: 0.4313\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 572us/step - loss: 0.4318 - val_loss: 0.4339\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 581us/step - loss: 0.4306 - val_loss: 0.4272\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 589us/step - loss: 0.4293 - val_loss: 0.4277\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 577us/step - loss: 0.4280 - val_loss: 0.4299\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 585us/step - loss: 0.4267 - val_loss: 0.4259\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 581us/step - loss: 0.4256 - val_loss: 0.4230\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 581us/step - loss: 0.4244 - val_loss: 0.4230\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 589us/step - loss: 0.4231 - val_loss: 0.4210\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 554us/step - loss: 0.4222 - val_loss: 0.4249\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.4211 - val_loss: 0.4261\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 559us/step - loss: 0.4201 - val_loss: 0.4237\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 588us/step - loss: 0.4191 - val_loss: 0.4212\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 536us/step - loss: 0.4181 - val_loss: 0.4198\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 589us/step - loss: 0.4172 - val_loss: 0.4236\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 593us/step - loss: 0.4162 - val_loss: 0.4300\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 536us/step - loss: 0.4153 - val_loss: 0.4291\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 548us/step - loss: 0.4144 - val_loss: 0.4259\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.4136 - val_loss: 0.4240\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 589us/step - loss: 0.4127 - val_loss: 0.4247\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 0.4118 - val_loss: 0.4204\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 548us/step - loss: 0.4111 - val_loss: 0.4238\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 523us/step - loss: 0.4103 - val_loss: 0.4234\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.4095 - val_loss: 0.4223\n",
      "121/121 [==============================] - 0s 297us/step - loss: 0.4111\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 778us/step - loss: 1.1468 - val_loss: 32.8823\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 499us/step - loss: 1.0995 - val_loss: 39.2808\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 532us/step - loss: 0.9155 - val_loss: 1.0402\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 542us/step - loss: 0.5354 - val_loss: 0.5935\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 546us/step - loss: 0.4908 - val_loss: 0.4855\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 540us/step - loss: 0.4654 - val_loss: 0.4400\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 538us/step - loss: 0.4488 - val_loss: 0.4142\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 551us/step - loss: 0.4361 - val_loss: 0.4050\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.4275 - val_loss: 0.4009\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 540us/step - loss: 0.4208 - val_loss: 0.3918\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.4150 - val_loss: 0.3884\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 499us/step - loss: 0.4100 - val_loss: 0.3867\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.4060 - val_loss: 0.3815\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 532us/step - loss: 0.4032 - val_loss: 0.3803\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.3999 - val_loss: 0.3801\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 532us/step - loss: 0.3972 - val_loss: 0.3832\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 545us/step - loss: 0.3948 - val_loss: 0.3841\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 536us/step - loss: 0.3926 - val_loss: 0.3923\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 512us/step - loss: 0.3901 - val_loss: 0.4125\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 523us/step - loss: 0.3886 - val_loss: 0.4167\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 499us/step - loss: 0.3872 - val_loss: 0.4025\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 528us/step - loss: 0.3855 - val_loss: 0.4098\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.3838 - val_loss: 0.4039\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 536us/step - loss: 0.3825 - val_loss: 0.4068\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 0.3808 - val_loss: 0.4069\n",
      "121/121 [==============================] - 0s 321us/step - loss: 0.3975\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 763us/step - loss: 1.2653 - val_loss: 2.0218\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 507us/step - loss: 0.6477 - val_loss: 2.3746\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 541us/step - loss: 0.5608 - val_loss: 2.2322\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 507us/step - loss: 0.5031 - val_loss: 2.0577\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 536us/step - loss: 0.4646 - val_loss: 1.6146\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.4424 - val_loss: 1.0609\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 490us/step - loss: 0.4308 - val_loss: 0.6916\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 515us/step - loss: 0.4222 - val_loss: 0.5308\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.4148 - val_loss: 0.4021\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 495us/step - loss: 0.4118 - val_loss: 0.3936\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 561us/step - loss: 0.4064 - val_loss: 0.4251\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 542us/step - loss: 0.4023 - val_loss: 0.4585\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 511us/step - loss: 0.4001 - val_loss: 0.5141\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 547us/step - loss: 0.3985 - val_loss: 0.6023\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 543us/step - loss: 0.3958 - val_loss: 0.6508\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 546us/step - loss: 0.3937 - val_loss: 0.7205\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 548us/step - loss: 0.3916 - val_loss: 0.7447\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 0.3905 - val_loss: 0.7885\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 511us/step - loss: 0.3879 - val_loss: 0.8405\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 532us/step - loss: 0.3871 - val_loss: 0.8459\n",
      "  1/121 [..............................] - ETA: 0s - loss: 0.2017WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "121/121 [==============================] - 0s 330us/step - loss: 0.4031\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 808us/step - loss: 1.0231 - val_loss: 56.1864\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 499us/step - loss: 0.9433 - val_loss: 94.8068\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 527us/step - loss: 0.9674 - val_loss: 0.8068\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 555us/step - loss: 0.4803 - val_loss: 0.4370\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 547us/step - loss: 0.4554 - val_loss: 0.4188\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 0.4429 - val_loss: 0.4061\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 540us/step - loss: 0.4343 - val_loss: 0.3956\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.4269 - val_loss: 0.3896\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 519us/step - loss: 0.4210 - val_loss: 0.3843\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 495us/step - loss: 0.4180 - val_loss: 0.3795\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.4134 - val_loss: 0.3760\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 548us/step - loss: 0.4099 - val_loss: 0.3759\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 519us/step - loss: 0.4073 - val_loss: 0.3735\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 550us/step - loss: 0.4050 - val_loss: 0.3718\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 515us/step - loss: 0.4029 - val_loss: 0.3693\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.4004 - val_loss: 0.3680\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 519us/step - loss: 0.3982 - val_loss: 0.3702\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.3962 - val_loss: 0.3732\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 519us/step - loss: 0.3949 - val_loss: 0.3834\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 528us/step - loss: 0.3932 - val_loss: 0.4052\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 0.3921 - val_loss: 0.4211\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 548us/step - loss: 0.3901 - val_loss: 0.4019\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 503us/step - loss: 0.3891 - val_loss: 0.3986\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 507us/step - loss: 0.3879 - val_loss: 0.4229\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 555us/step - loss: 0.3872 - val_loss: 0.3868\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 548us/step - loss: 0.3851 - val_loss: 0.3903\n",
      "  1/121 [..............................] - ETA: 0s - loss: 0.3689WARNING:tensorflow:Callbacks method `on_test_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_begin` time: 0.0010s). Check your callbacks.\n",
      "121/121 [==============================] - 0s 294us/step - loss: 0.3850\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 762us/step - loss: 5.9948 - val_loss: 28.9576\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 519us/step - loss: 4.5048 - val_loss: 19.2947\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 532us/step - loss: 3.4326 - val_loss: 13.0536\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 532us/step - loss: 2.6580 - val_loss: 8.9791\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 687us/step - loss: 2.0953 - val_loss: 6.3011\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 534us/step - loss: 1.6849 - val_loss: 4.5516\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 498us/step - loss: 1.3845 - val_loss: 3.3773\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 490us/step - loss: 1.1639 - val_loss: 2.5833\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 528us/step - loss: 1.0013 - val_loss: 2.0237\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 525us/step - loss: 0.8810 - val_loss: 1.6534\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 546us/step - loss: 0.7920 - val_loss: 1.3961\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 547us/step - loss: 0.7259 - val_loss: 1.1988\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 503us/step - loss: 0.6765 - val_loss: 1.0748\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 522us/step - loss: 0.6398 - val_loss: 0.9871\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 532us/step - loss: 0.6124 - val_loss: 0.9114\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.5917 - val_loss: 0.8629\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 0.5762 - val_loss: 0.8289\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 857us/step - loss: 0.5646 - val_loss: 0.8065\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 670us/step - loss: 0.5558 - val_loss: 0.7913\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 508us/step - loss: 0.5492 - val_loss: 0.7802\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 0.5442 - val_loss: 0.7623\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 495us/step - loss: 0.5403 - val_loss: 0.7581\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 0.5374 - val_loss: 0.7550\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 490us/step - loss: 0.5351 - val_loss: 0.7531\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 490us/step - loss: 0.5335 - val_loss: 0.7479\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 536us/step - loss: 0.5321 - val_loss: 0.7388\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 462us/step - loss: 0.5310 - val_loss: 0.7459\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 573us/step - loss: 0.5302 - val_loss: 0.7380\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 490us/step - loss: 0.5296 - val_loss: 0.7416\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 536us/step - loss: 0.5291 - val_loss: 0.7400\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 535us/step - loss: 0.5287 - val_loss: 0.7387\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.5284 - val_loss: 0.7339\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 528us/step - loss: 0.5281 - val_loss: 0.7380\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 0.5279 - val_loss: 0.7401\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 501us/step - loss: 0.5278 - val_loss: 0.7335\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 493us/step - loss: 0.5275 - val_loss: 0.7413\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 528us/step - loss: 0.5275 - val_loss: 0.7180\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 528us/step - loss: 0.5273 - val_loss: 0.7317\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 503us/step - loss: 0.5273 - val_loss: 0.7288\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 507us/step - loss: 0.5272 - val_loss: 0.7318\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 503us/step - loss: 0.5270 - val_loss: 0.7403\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 528us/step - loss: 0.5271 - val_loss: 0.7351\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 523us/step - loss: 0.5270 - val_loss: 0.7306\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 0.5269 - val_loss: 0.7410\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.5269 - val_loss: 0.7440\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 530us/step - loss: 0.5268 - val_loss: 0.7408\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 542us/step - loss: 0.5267 - val_loss: 0.7476\n",
      "121/121 [==============================] - 0s 330us/step - loss: 0.5426\n",
      "Epoch 1/100\n",
      "159/242 [==================>...........] - ETA: 0s - loss: 6.7949WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "242/242 [==============================] - 0s 746us/step - loss: 6.5340 - val_loss: 18.8596\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 5.1213 - val_loss: 16.0361\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 515us/step - loss: 4.0671 - val_loss: 13.6839\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 515us/step - loss: 3.2767 - val_loss: 11.7045\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 528us/step - loss: 2.6808 - val_loss: 10.0221\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 495us/step - loss: 2.2294 - val_loss: 8.5819\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 532us/step - loss: 1.8859 - val_loss: 7.3396\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 528us/step - loss: 1.6234 - val_loss: 6.2618\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 532us/step - loss: 1.4215 - val_loss: 5.3278\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 523us/step - loss: 1.2655 - val_loss: 4.5163\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 511us/step - loss: 1.1442 - val_loss: 3.8096\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 523us/step - loss: 1.0492 - val_loss: 3.1973\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 506us/step - loss: 0.9743 - val_loss: 2.6687\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 0.9148 - val_loss: 2.2182\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 503us/step - loss: 0.8672 - val_loss: 1.8359\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 495us/step - loss: 0.8287 - val_loss: 1.5157\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 536us/step - loss: 0.7972 - val_loss: 1.2532\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.7713 - val_loss: 1.0431\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 495us/step - loss: 0.7498 - val_loss: 0.8813\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 523us/step - loss: 0.7317 - val_loss: 0.7647\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 490us/step - loss: 0.7163 - val_loss: 0.6891\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 532us/step - loss: 0.7031 - val_loss: 0.6521\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 501us/step - loss: 0.6916 - val_loss: 0.6504\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 519us/step - loss: 0.6814 - val_loss: 0.6812\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 530us/step - loss: 0.6725 - val_loss: 0.7422\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 521us/step - loss: 0.6645 - val_loss: 0.8309\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 499us/step - loss: 0.6573 - val_loss: 0.9454\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 503us/step - loss: 0.6507 - val_loss: 1.0829\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.6446 - val_loss: 1.2427\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.6390 - val_loss: 1.4226\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.6339 - val_loss: 1.6197\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 507us/step - loss: 0.6290 - val_loss: 1.8327\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 536us/step - loss: 0.6245 - val_loss: 2.0607\n",
      "121/121 [==============================] - 0s 288us/step - loss: 0.6583\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 802us/step - loss: 7.1766 - val_loss: 22.5237\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 515us/step - loss: 5.3101 - val_loss: 14.2555\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 490us/step - loss: 3.9997 - val_loss: 9.0716\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 517us/step - loss: 3.0733 - val_loss: 5.7918\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 532us/step - loss: 2.4124 - val_loss: 3.8035\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 528us/step - loss: 1.9399 - val_loss: 2.5581\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 455us/step - loss: 1.5992 - val_loss: 1.7932\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 1.3526 - val_loss: 1.3304\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 495us/step - loss: 1.1734 - val_loss: 1.0720\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 503us/step - loss: 1.0429 - val_loss: 0.9310\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 528us/step - loss: 0.9471 - val_loss: 0.8586\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 519us/step - loss: 0.8764 - val_loss: 0.8277\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 515us/step - loss: 0.8240 - val_loss: 0.8177\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 453us/step - loss: 0.7848 - val_loss: 0.8253\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 497us/step - loss: 0.7551 - val_loss: 0.8345\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 493us/step - loss: 0.7324 - val_loss: 0.8585\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 511us/step - loss: 0.7150 - val_loss: 0.8726\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 502us/step - loss: 0.7013 - val_loss: 0.8840\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 497us/step - loss: 0.6904 - val_loss: 0.9108\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 511us/step - loss: 0.6817 - val_loss: 0.9230\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 519us/step - loss: 0.6743 - val_loss: 0.9326\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 490us/step - loss: 0.6681 - val_loss: 0.9428\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 515us/step - loss: 0.6628 - val_loss: 0.9394\n",
      "121/121 [==============================] - 0s 280us/step - loss: 0.6714\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 890us/step - loss: 1.2627 - val_loss: 6.9508\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 585us/step - loss: 0.6350 - val_loss: 3.0937\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 592us/step - loss: 0.5090 - val_loss: 0.4519\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 596us/step - loss: 0.4443 - val_loss: 0.4112\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 585us/step - loss: 0.4238 - val_loss: 0.3995\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 569us/step - loss: 0.4095 - val_loss: 0.4151\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 540us/step - loss: 0.3996 - val_loss: 0.3884\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 0.3919 - val_loss: 0.4242\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.3866 - val_loss: 0.4033\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 581us/step - loss: 0.3815 - val_loss: 0.4112\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 585us/step - loss: 0.3780 - val_loss: 0.3615\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 580us/step - loss: 0.3733 - val_loss: 0.3713\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 569us/step - loss: 0.3696 - val_loss: 0.3994\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 569us/step - loss: 0.3672 - val_loss: 0.4135\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 616us/step - loss: 0.3648 - val_loss: 0.3665\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 614us/step - loss: 0.3620 - val_loss: 0.3940\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 583us/step - loss: 0.3594 - val_loss: 0.3949\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 612us/step - loss: 0.3575 - val_loss: 0.3896\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 605us/step - loss: 0.3551 - val_loss: 0.3774\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 587us/step - loss: 0.3531 - val_loss: 0.3840\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 577us/step - loss: 0.3515 - val_loss: 0.3613\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 598us/step - loss: 0.3498 - val_loss: 0.3865\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 593us/step - loss: 0.3482 - val_loss: 0.3583\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 593us/step - loss: 0.3466 - val_loss: 0.3413\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 643us/step - loss: 0.3445 - val_loss: 0.3840\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 655us/step - loss: 0.3435 - val_loss: 0.3334\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 548us/step - loss: 0.3424 - val_loss: 0.3875\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 547us/step - loss: 0.3416 - val_loss: 0.3632\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 577us/step - loss: 0.3388 - val_loss: 0.3535\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 625us/step - loss: 0.3387 - val_loss: 0.3310\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 569us/step - loss: 0.3375 - val_loss: 0.3472\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.3360 - val_loss: 0.3246\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 0.3345 - val_loss: 0.3724\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 0.3339 - val_loss: 0.3218\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 569us/step - loss: 0.3329 - val_loss: 0.3617\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 0.3323 - val_loss: 0.4588\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 598us/step - loss: 0.3315 - val_loss: 0.4230\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 589us/step - loss: 0.3316 - val_loss: 0.4987\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 575us/step - loss: 0.3316 - val_loss: 0.3842\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 580us/step - loss: 0.3296 - val_loss: 0.4544\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 538us/step - loss: 0.3288 - val_loss: 0.3235\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 593us/step - loss: 0.3266 - val_loss: 0.3255\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 573us/step - loss: 0.3261 - val_loss: 0.3158\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 577us/step - loss: 0.3243 - val_loss: 0.3654\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 593us/step - loss: 0.3250 - val_loss: 0.3309\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 598us/step - loss: 0.3235 - val_loss: 0.3752\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.3219 - val_loss: 0.3192\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 589us/step - loss: 0.3211 - val_loss: 0.3414\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 599us/step - loss: 0.3200 - val_loss: 0.3191\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 596us/step - loss: 0.3198 - val_loss: 0.4169\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 587us/step - loss: 0.3191 - val_loss: 0.3186\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 565us/step - loss: 0.3174 - val_loss: 0.3393\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 610us/step - loss: 0.3173 - val_loss: 0.3155\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 580us/step - loss: 0.3158 - val_loss: 0.3106\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 577us/step - loss: 0.3144 - val_loss: 0.3532\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 523us/step - loss: 0.3164 - val_loss: 0.4813\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 523us/step - loss: 0.3159 - val_loss: 0.5978\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 528us/step - loss: 0.3167 - val_loss: 0.3232\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 511us/step - loss: 0.3127 - val_loss: 0.3348\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 569us/step - loss: 0.3114 - val_loss: 0.3063\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 589us/step - loss: 0.3112 - val_loss: 0.3701\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 0.3101 - val_loss: 0.3195\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.3098 - val_loss: 0.3148\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 555us/step - loss: 0.3088 - val_loss: 0.3650\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 577us/step - loss: 0.3092 - val_loss: 0.3056\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 563us/step - loss: 0.3085 - val_loss: 0.3149\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 565us/step - loss: 0.3070 - val_loss: 0.3294\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 532us/step - loss: 0.3064 - val_loss: 0.3197\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.3055 - val_loss: 0.3108\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 576us/step - loss: 0.3053 - val_loss: 0.3149\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 548us/step - loss: 0.3048 - val_loss: 0.2980\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 532us/step - loss: 0.3034 - val_loss: 0.3515\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 540us/step - loss: 0.3043 - val_loss: 0.4575\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 523us/step - loss: 0.3051 - val_loss: 0.6223\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 536us/step - loss: 0.3065 - val_loss: 0.3572\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 519us/step - loss: 0.3025 - val_loss: 0.4693\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 536us/step - loss: 0.3035 - val_loss: 0.4335\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 532us/step - loss: 0.3019 - val_loss: 0.5367\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 533us/step - loss: 0.3075 - val_loss: 0.4715\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 528us/step - loss: 0.3011 - val_loss: 0.4992\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 528us/step - loss: 0.3032 - val_loss: 0.3648\n",
      "121/121 [==============================] - 0s 326us/step - loss: 0.3342\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.1687 - val_loss: 11.5619\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 523us/step - loss: 0.6074 - val_loss: 2.7019\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 523us/step - loss: 0.5098 - val_loss: 0.5926\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 528us/step - loss: 0.4609 - val_loss: 0.4158\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 525us/step - loss: 0.4340 - val_loss: 0.3970\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 515us/step - loss: 0.4180 - val_loss: 0.3937\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 522us/step - loss: 0.4079 - val_loss: 0.4369\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 511us/step - loss: 0.3991 - val_loss: 0.5232\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 515us/step - loss: 0.3923 - val_loss: 0.6559\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 503us/step - loss: 0.3878 - val_loss: 0.7230\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 503us/step - loss: 0.3827 - val_loss: 0.7905\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 503us/step - loss: 0.3783 - val_loss: 0.8594\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 511us/step - loss: 0.3758 - val_loss: 0.9830\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 511us/step - loss: 0.3731 - val_loss: 1.1008\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 503us/step - loss: 0.3704 - val_loss: 1.1484\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 503us/step - loss: 0.3673 - val_loss: 1.2088\n",
      "121/121 [==============================] - 0s 288us/step - loss: 0.3894\n",
      "Epoch 1/100\n",
      "  1/242 [..............................] - ETA: 0s - loss: 7.3371WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_begin` time: 0.0010s). Check your callbacks.\n",
      "242/242 [==============================] - 0s 835us/step - loss: 1.3918 - val_loss: 0.7525\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 518us/step - loss: 0.6525 - val_loss: 0.5687\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 513us/step - loss: 0.5624 - val_loss: 0.5078\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 528us/step - loss: 0.5084 - val_loss: 0.5716\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 618us/step - loss: 0.4734 - val_loss: 0.5369\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 0.4468 - val_loss: 0.5797\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 515us/step - loss: 0.4313 - val_loss: 0.5132\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 499us/step - loss: 0.4181 - val_loss: 0.4781\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.4087 - val_loss: 0.3830\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 596us/step - loss: 0.4038 - val_loss: 0.4038\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 528us/step - loss: 0.3939 - val_loss: 0.7354\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 539us/step - loss: 0.3940 - val_loss: 0.4818\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 528us/step - loss: 0.3860 - val_loss: 0.4408\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 520us/step - loss: 0.3815 - val_loss: 0.4138\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 529us/step - loss: 0.3784 - val_loss: 0.3721\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 592us/step - loss: 0.3744 - val_loss: 0.5602\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 528us/step - loss: 0.3756 - val_loss: 0.4822\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 523us/step - loss: 0.3710 - val_loss: 0.5670\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 515us/step - loss: 0.3704 - val_loss: 0.3472\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 519us/step - loss: 0.3650 - val_loss: 0.4732\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 511us/step - loss: 0.3652 - val_loss: 0.3595\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 515us/step - loss: 0.3619 - val_loss: 0.3976\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 532us/step - loss: 0.3605 - val_loss: 0.3552\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 515us/step - loss: 0.3590 - val_loss: 0.6033\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 523us/step - loss: 0.3598 - val_loss: 0.4935\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 528us/step - loss: 0.3578 - val_loss: 0.6084\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 525us/step - loss: 0.3574 - val_loss: 0.3465\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 532us/step - loss: 0.3537 - val_loss: 0.3907\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 532us/step - loss: 0.3552 - val_loss: 0.3903\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 528us/step - loss: 0.3533 - val_loss: 0.3757\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 532us/step - loss: 0.3508 - val_loss: 0.3440\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 0.3495 - val_loss: 0.4578\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 532us/step - loss: 0.3499 - val_loss: 0.3373\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.3482 - val_loss: 0.4987\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 528us/step - loss: 0.3507 - val_loss: 0.4142\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 548us/step - loss: 0.3476 - val_loss: 0.7444\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 521us/step - loss: 0.3485 - val_loss: 0.5017\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 535us/step - loss: 0.3517 - val_loss: 0.9424\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 523us/step - loss: 0.3499 - val_loss: 0.4563\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 527us/step - loss: 0.3460 - val_loss: 0.8955\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 532us/step - loss: 0.3517 - val_loss: 0.5259\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 519us/step - loss: 0.3464 - val_loss: 0.9797\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 523us/step - loss: 0.3468 - val_loss: 0.6487\n",
      "121/121 [==============================] - 0s 305us/step - loss: 0.3416\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x00000218972B3460>, as the constructor either does not set or modifies parameter learning_rate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-123-9965911acea0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mrnd_search_cv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras_reg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_distribs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m rnd_search_cv.fit(X_train, y_train, epochs = 100,\n\u001b[0m\u001b[0;32m     12\u001b[0m                  \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m                  callbacks = [keras.callbacks.EarlyStopping(patience = 10)])\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    759\u001b[0m             \u001b[1;31m# we clone again after setting params in case some\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    760\u001b[0m             \u001b[1;31m# of the params are estimators as well.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 761\u001b[1;33m             self.best_estimator_ = clone(clone(base_estimator).set_params(\n\u001b[0m\u001b[0;32m    762\u001b[0m                 **self.best_params_))\n\u001b[0;32m    763\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mclone\u001b[1;34m(estimator, safe)\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[0mparam2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparams_set\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mparam1\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mparam2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m             raise RuntimeError('Cannot clone object %s, as the constructor '\n\u001b[0m\u001b[0;32m     97\u001b[0m                                \u001b[1;34m'either does not set or modifies parameter %s'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m                                (estimator, name))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x00000218972B3460>, as the constructor either does not set or modifies parameter learning_rate"
     ]
    }
   ],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_hidden\" : [0, 1, 2, 3],\n",
    "    \"n_neurons\" : np.arange(1, 100),\n",
    "    \"learning_rate\" : reciprocal(3e-4, 3e-2),\n",
    "}\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter = 10, cv = 3)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs = 100,\n",
    "                 validation_data = (X_valid, y_valid),\n",
    "                 callbacks = [keras.callbacks.EarlyStopping(patience = 10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.0033625641252688094, 'n_hidden': 2, 'n_neurons': 42}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#최상의 하이퍼 파라미터와 훈련된 케라스 모델\n",
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.3551027576128642"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RandomizedSearchCV' object has no attribute 'best_estimator_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-132-3b40e07bb81d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrnd_search_cv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'RandomizedSearchCV' object has no attribute 'best_estimator_'"
     ]
    }
   ],
   "source": [
    "rnd_search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RandomizedSearchCV' object has no attribute 'best_estimator_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-133-f89828bd4b63>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnd_search_cv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'RandomizedSearchCV' object has no attribute 'best_estimator_'"
     ]
    }
   ],
   "source": [
    "model = rnd_search_cv.best_estimator_.model\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 486us/step - loss: 0.3727\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.37267106771469116"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 하이퍼 파라미터 최적화에 사용할 수 있는 파이썬 라이브러리\n",
    "- Hyperopt : 모든 종류의 복잡한 탐색 공간에 대해 최적화를 수행할 수 있는 잘 알려진 라이브러리\n",
    "- Hyperas, kopt, Talos : 케라스 모델을 위한 하이퍼 파라미터 최적화 라이브러리\n",
    "- Scikit-Optimize(skopt) : 범용 최적화 라이브러리. BayeSearchCV 클래스는 GridSearchCV와 비슷한 인터페이스 사용하여 베이즈 최적화를 수행\n",
    "- Spearmint : 베이즈 최적화 라이브러리\n",
    "- Hyperband : 리샤 리 등의 최근  Hyperband 논문을 기반으로 구축된 빠른 하이퍼 파라미터 튜닝 라이브러리\n",
    "- Sklearn-Deap : GridSearchCV와 비슷한 인터페이스를 가진 진화 알고리즘 기반의 하이퍼 파라미터 최적화 라이브러리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  10.3.1 은닉층 개수\n",
    "\n",
    "* 복잡한 문제에서는 심층 신경망이 얕은 신경망보다 파라미터 효율성(Parameter Efficiency)가 더 좋다\n",
    "* 아래쪽 은닉층은 저수준의 구조를 모델링하고, 중간 은닉층은 저수준의 구조를 연결해 중간 수준의 구조를 모델링한다. 그리고 가장 위쪽 은닉층과 출력층은 중간 수준의 구조를 연결하고 고수준의 구조를 모델링한다.\n",
    "* 전이학습(Transfer Learning) : 새로운 신경망에서 처음 몇 개 층의 가중치와 편향을 난수로 초기화하는 대신 첫 번째 신경망의 층에 있는 가중치와 편향값으로 초기화하는 방식"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.3.2 은닉층의 뉴런 개수\n",
    "\n",
    "* 은닉층의 구성 방식은 일반적으로 각 층의 뉴런을 점점 줄여서 깔때기처럼 구성한다.\n",
    "* 저수준의 많은 특성이 고수준의 적은 특성으로 합쳐질 수 있기 때문\n",
    "* 층의 개수와 마찬가지로 네트워크가 과대적합이 시작되기 전까지 점진적으로 뉴런 수를 늘릴 수 있다.\n",
    "* 하지만 실전에서는 필요한 것보다 더 많은 층과 뉴런을 가진 모델을 선택하고, 그런 다음 과대적합되지 않도록 조기 종료나 규제 기법을 사용하는 것이 더 효과적이고 간단하다.\n",
    "* 한 층의 뉴런 수가 너무 적으면 입력에 있는 유용한 정보를 모두 유지하기 위한 충분한 표현 능력을 가지지 못한다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.3.3 학습률, 배치 크기 그리고 다른 하이퍼파라미터\n",
    "\n",
    "* 학습률\n",
    " - 일반적으로 최적의 학습률은 최대 학습률의 절반 정도\n",
    " - 좋은 학습률을 찾는 한 가지 방법은 매우 낮은 학습률에서 시작해서 점진적으로 매우 큰 학습률까지 수백번 반복하여 모델을 훈련하는 것\n",
    " \n",
    "* 옵티마이저\n",
    " - 고전적인 평범한 미니배치 경사 하강법보다 더 좋은 옵티마이저를 선택하는 것도 중요하다\n",
    " \n",
    "* 배치 크기\n",
    " - 큰 배치 크기를 사용하는 것의 주요 장점은 GPU와 같은 하드웨어 가속기를 효율적으로 활용할 수 있다.\n",
    " - 실전에서 큰 배치 크기를 사용하면 특히 훈련 초기에 종종 불안정하게 훈련된다.\n",
    " - 큰 배치 크기는 일반화 성능에 영향을 미치지 않고, 훈련 시간을 매우 단축시킨다.\n",
    " - 훈련이 불안정하거나 최종 성능이 만족스럽지 못하면 작은 배치 크기를 사용\n",
    " \n",
    "* 활성화 함수\n",
    " - 일반적으로 ReLU 활성화 함수가 모든 은닉층에 좋은 기본값\n",
    " - 출력층의 활성화 함수는 수행하는 작업에 따라 달라진다.\n",
    "\n",
    "* 반복 횟수\n",
    " - 대부분의 경우 훈련 반복 횟수는 튜닝할 필요가 없다. 대신 조기 종료를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
